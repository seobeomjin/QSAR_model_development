{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioalerts\n",
    "from bioalerts import LoadMolecules, Alerts, FPCalculator\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole \n",
    "from rdkit.Chem import PandasTools \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor #knn\n",
    "from sklearn.ensemble import RandomForestRegressor #RF\n",
    "from sklearn.svm import SVR #SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_path = \"./tutorial/datasets/androgen.smi\"\n",
    "bio_path = './tutorial/datasets/androgen.bio.txt'\n",
    "\n",
    "wdir =  'C:/jupyter_devel/kist-europe/QSAR/AOP_data/'\n",
    "csv = 'cleandata_androgen_ec50_check-maccs-remcols-stdval.csv'\n",
    "result_wdir = 'C:/jupyter_devel/kist-europe/QSAR/AOP_data/model_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(wdir+csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Standard Value']\n",
    "x = df.drop(['Molecule','Standard Value'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x104dd9b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ = range(len(x))\n",
    "plt.scatter(x_,y)\n",
    "#plt.ylim(0,50000)\n",
    "\n",
    "#### PIC transformation Formula ####\n",
    "# PIC = 9 - np.log10(actual activity)\n",
    "# actual activity = np,power(10,9-PIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. calculate significant substructure feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = bioalerts.LoadMolecules.LoadMolecules(smiles_path,name_field=None)\n",
    "molecules.ReadMolecules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_bio = np.genfromtxt(bio_path,skip_header=0) \n",
    "cox_bio.shape\n",
    "arr = np.arange(0,len(cox_bio))\n",
    "mask = np.ones(arr.shape,dtype=bool)\n",
    "mask[molecules.molserr]=0\n",
    "cox_bio = cox_bio[mask]\n",
    "print len(cox_bio)\n",
    "print len(molecules.mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = bioalerts.LoadMolecules.GetDataSetInfo(name_field=None)\n",
    "dataset_info.extract_substructure_information(radii=[2,3,4,5,6],mols=molecules.mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alerts_continuous_high_activity = bioalerts.Alerts.CalculatePvaluesContinuous(radii_ext=[2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bioactivity_threshold(bio,threshold):\n",
    "    # a pIC50 is smaller, higher activity \n",
    "    \n",
    "    sorted_bio = sorted(bio)\n",
    "    threshold_bio_value = sorted_bio[int(len(sorted_bio)*threshold)]\n",
    "    \n",
    "    print(\"activity ratio is {}\".format(1-threshold))\n",
    "    print(\"threshold value is {}\".format(threshold_bio_value))\n",
    "    print(\"actual bioactivity value is {}\".format(np.power(10,9 - threshold_bio_value)))\n",
    "    return threshold_bio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_= 0.33\n",
    "threshold_bio_value = calculate_bioactivity_threshold(cox_bio,threshold_)\n",
    "\n",
    "threshold_nb_substructures = 10\n",
    "threshold_ratio = 0.3\n",
    "threshold_high_act_nb_substructures = 5 #5\n",
    "threshold_high_act_ratio = 0.29 #0.5                                                                  \n",
    "\n",
    "# maybe no necessary to change\n",
    "threshold_pvalue = 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_substructure = {}\n",
    "significant_substructure = Alerts_continuous_high_activity.get_significant_substructure_with_high_bioactivity(\n",
    "mols = molecules.mols,\n",
    "     substructure_dictionary = dataset_info.substructure_dictionary,\n",
    "     bioactivities = cox_bio,\n",
    "     mols_ids = molecules.mols_ids[:],\n",
    "     threshold_nb_substructures = threshold_nb_substructures,\n",
    "     threshold_pvalue = threshold_pvalue,\n",
    "     threshold_ratio=threshold_ratio,\n",
    "     threshold_high_act_nb_substructures=threshold_high_act_nb_substructures,\n",
    "     threshold_high_act_ratio = threshold_high_act_ratio,                                                                        \n",
    "     threshold_bioactivity=threshold_bio_value)\n",
    "\n",
    "#threshold_high_act_nb_substructure = N of molecules involved significant substructure with high activity  \n",
    "#threshold_high_act_ratio = N of molecules involved significant substructure with high activity / N of molecules involved significant substructure\n",
    "#threshold_bioactivity = Top 40% by total bioactivity\n",
    "\n",
    "#return value is significant_substructure dictionary with high activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_id_set = set()\n",
    "for k,v in significant_substructure.items():\n",
    "    for mol_id in v: \n",
    "        mol_id_set.add(mol_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of total substructure : {}'.format(len(dataset_info.substructure_dictionary)))\n",
    "print('number of extracted significant substructure : {}'.format(len(significant_substructure)))\n",
    "print('{} out of {} have the label which represent remaining significant substructure\\n'.format(len(mol_id_set),len(cox_bio)))\n",
    "\n",
    "print ('THRESHOLD - \\n\\tnumber of substructures : {}\\n\\tp value : {}\\n\\tratio : {}\\n\\tnumber of high activity threshold : {}\\n\\thigh activity ratio : {}\\n\\thigh bioactivity threshold : {}'\n",
    "       .format(threshold_nb_substructures,threshold_pvalue,threshold_ratio,threshold_high_act_nb_substructures,threshold_high_act_ratio,threshold_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code when you repair hyperparameter\n",
    "if len(significant_substructure) is not 0 :\n",
    "    significant_substructure.clear()\n",
    "if len(mol_id_set) is not 0 :\n",
    "    mol_id_set.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. insert feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pic50 = 9 - np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert feature into only train dataset\n",
    "for iter_ in x.index:\n",
    "    for i in range(8): \n",
    "        if iter_ in mol_id_set : \n",
    "            x.loc[iter_,'significant_feature_{}'.format(i)] = 1.0\n",
    "        else :\n",
    "            x.loc[iter_,'significant_feature_{}'.format(i)] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_pic50,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_idx = []\n",
    "for row in x_test.index:\n",
    "    x_test_idx.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.1.1 KNN hyperparameter search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chon0\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to bool by check_pairwise_arrays.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bset Parameters set found on GridSearch CV :\n",
      "\n",
      "{'n_neighbors': 5, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors':[4,5,6,7,8],\n",
    "              'algorithm':['auto','ball_tree','brute'],\n",
    "              'metric':['jaccard','matching','dice'],\n",
    "             'weights':['uniform','distance']} \n",
    "KNN_search = GridSearchCV(neigh,param_grid,cv=5)\n",
    "KNN_search.fit(x_train,y_train)\n",
    "print(\"Bset Parameters set found on GridSearch CV :\\n\")\n",
    "print(KNN_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on GridSearchCV :\n",
      "\n",
      "0.281 (+/-0.231) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.300 (+/-0.208) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.283 (+/-0.193) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.312 (+/-0.175) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.282 (+/-0.155) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.316 (+/-0.153) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.269 (+/-0.160) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.310 (+/-0.141) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.270 (+/-0.146) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.311 (+/-0.135) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.329 (+/-0.171) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.338 (+/-0.169) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.300 (+/-0.180) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.336 (+/-0.162) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.280 (+/-0.142) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.325 (+/-0.141) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.294 (+/-0.098) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.338 (+/-0.108) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.278 (+/-0.094) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.329 (+/-0.101) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.281 (+/-0.231) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.303 (+/-0.206) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.283 (+/-0.193) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.315 (+/-0.173) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.282 (+/-0.155) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.319 (+/-0.152) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.269 (+/-0.160) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.313 (+/-0.140) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.270 (+/-0.146) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'auto'}\n",
      "0.315 (+/-0.135) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'auto'}\n",
      "0.281 (+/-0.231) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.300 (+/-0.208) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.283 (+/-0.193) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.312 (+/-0.175) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.282 (+/-0.155) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.316 (+/-0.153) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.269 (+/-0.160) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.310 (+/-0.141) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.270 (+/-0.146) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.311 (+/-0.135) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.329 (+/-0.171) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.338 (+/-0.169) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.300 (+/-0.180) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.336 (+/-0.162) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.280 (+/-0.142) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.325 (+/-0.141) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.294 (+/-0.098) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.338 (+/-0.108) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.278 (+/-0.094) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.329 (+/-0.101) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.281 (+/-0.231) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.303 (+/-0.206) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.283 (+/-0.193) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.315 (+/-0.173) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.282 (+/-0.155) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.319 (+/-0.152) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.269 (+/-0.160) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.313 (+/-0.140) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.270 (+/-0.146) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'ball_tree'}\n",
      "0.315 (+/-0.135) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'ball_tree'}\n",
      "0.286 (+/-0.233) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.304 (+/-0.211) for {'n_neighbors': 4, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.297 (+/-0.202) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.325 (+/-0.175) for {'n_neighbors': 5, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.286 (+/-0.152) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.320 (+/-0.152) for {'n_neighbors': 6, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.271 (+/-0.161) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.312 (+/-0.139) for {'n_neighbors': 7, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.277 (+/-0.138) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.316 (+/-0.136) for {'n_neighbors': 8, 'metric': 'jaccard', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.327 (+/-0.171) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.343 (+/-0.152) for {'n_neighbors': 4, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.311 (+/-0.160) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.345 (+/-0.144) for {'n_neighbors': 5, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.297 (+/-0.127) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.340 (+/-0.127) for {'n_neighbors': 6, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.297 (+/-0.087) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.340 (+/-0.091) for {'n_neighbors': 7, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.294 (+/-0.070) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.340 (+/-0.080) for {'n_neighbors': 8, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.286 (+/-0.233) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.307 (+/-0.209) for {'n_neighbors': 4, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.297 (+/-0.202) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.328 (+/-0.173) for {'n_neighbors': 5, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.286 (+/-0.152) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.323 (+/-0.151) for {'n_neighbors': 6, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.271 (+/-0.161) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.315 (+/-0.138) for {'n_neighbors': 7, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'brute'}\n",
      "0.277 (+/-0.138) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'uniform', 'algorithm': 'brute'}\n",
      "0.319 (+/-0.135) for {'n_neighbors': 8, 'metric': 'dice', 'weights': 'distance', 'algorithm': 'brute'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Grid scores on GridSearchCV :\\n\")\n",
    "\n",
    "means = KNN_search.cv_results_['mean_test_score']\n",
    "stds = KNN_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, KNN_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search_pred = KNN_search.predict(x_test)\n",
    "\n",
    "# test rseult \n",
    "print(\"\\ntest RMSE : {}\".format(round(np.sqrt(mean_squared_error(y_test,knn_search_pred)),4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'brute',\n",
       " 'metric': 'matching',\n",
       " 'n_neighbors': 5,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.1.2 KNN model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 0\n",
      "iteration num : 1\n",
      "iteration num : 2\n",
      "iteration num : 3\n",
      "iteration num : 4\n",
      "[1.0504, 1.3656, 1.0345, 1.2952, 1.2829]\n",
      "('mean : ', 1.20572)\n",
      "iteration num : 5\n",
      "iteration num : 6\n",
      "iteration num : 7\n",
      "iteration num : 8\n",
      "iteration num : 9\n",
      "[1.3984, 1.0851, 1.1218, 1.4333, 1.244]\n",
      "('mean : ', 1.25652)\n",
      "iteration num : 10\n",
      "iteration num : 11\n",
      "iteration num : 12\n",
      "iteration num : 13\n",
      "iteration num : 14\n",
      "[1.101, 1.2689, 1.4575, 1.3115, 1.1448]\n",
      "('mean : ', 1.25674)\n",
      "iteration num : 15\n",
      "iteration num : 16\n",
      "iteration num : 17\n",
      "iteration num : 18\n",
      "iteration num : 19\n",
      "[1.2328, 1.2237, 1.2711, 1.3236, 1.297]\n",
      "('mean : ', 1.2696399999999999)\n",
      "iteration num : 20\n",
      "iteration num : 21\n",
      "iteration num : 22\n",
      "iteration num : 23\n",
      "iteration num : 24\n",
      "[1.2214, 1.219, 1.2938, 1.0986, 1.252]\n",
      "('mean : ', 1.21696)\n",
      "iteration num : 25\n",
      "iteration num : 26\n",
      "iteration num : 27\n",
      "iteration num : 28\n",
      "iteration num : 29\n",
      "[1.2236, 1.2892, 1.3254, 1.0816, 1.1107]\n",
      "('mean : ', 1.2061)\n",
      "iteration num : 30\n",
      "iteration num : 31\n",
      "iteration num : 32\n",
      "iteration num : 33\n",
      "iteration num : 34\n",
      "[1.3343, 1.1243, 1.0686, 1.2017, 1.4538]\n",
      "('mean : ', 1.2365400000000002)\n",
      "iteration num : 35\n",
      "iteration num : 36\n",
      "iteration num : 37\n",
      "iteration num : 38\n",
      "iteration num : 39\n",
      "[1.3212, 1.1727, 1.1969, 1.4921, 1.2619]\n",
      "('mean : ', 1.2889599999999999)\n",
      "iteration num : 40\n",
      "iteration num : 41\n",
      "iteration num : 42\n",
      "iteration num : 43\n",
      "iteration num : 44\n",
      "[1.2742, 1.0701, 1.3638, 1.1835, 1.3384]\n",
      "('mean : ', 1.246)\n",
      "iteration num : 45\n",
      "iteration num : 46\n",
      "iteration num : 47\n",
      "iteration num : 48\n",
      "iteration num : 49\n",
      "[1.1799, 1.2378, 1.3193, 1.0641, 1.3097]\n",
      "('mean : ', 1.2221600000000001)\n",
      "('total fold mean : ', 1.2405)\n",
      "('total cv mean : ', 1.2405)\n"
     ]
    }
   ],
   "source": [
    "#fold setting\n",
    "kf = RepeatedKFold(n_splits = 5,n_repeats=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#for numbering k folds\n",
    "k=0\n",
    "cv_rmse = []\n",
    "cv_rmse_mean = []\n",
    "tmp = []\n",
    "\n",
    "#DataFrame generate\n",
    "y_pic_pred_result = pd.DataFrame()\n",
    "y_pic_pred_result['idx'] = pd.Series([i for i in range(len(y))])\n",
    "\n",
    "\n",
    "##################    using hyperparameter tuning model    ##################    \n",
    "#model generate\n",
    "neigh = KNeighborsRegressor(n_neighbors = 5, metric='matching',weights='distance',algorithm='brute')\n",
    "#KNN without sig, for androgen {'n_neighbors': 5, 'metric': 'matching', 'weights': 'distance', 'algorithm': 'brute'}\n",
    "##################    using hyperparameter tuning model    ##################\n",
    "\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    #print(\"iteration num : {}\".format(k))\n",
    "    #print(\"train : \", train_idx, \"\\ntest : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    neigh.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = neigh.predict(x_cv_test)\n",
    "    cv_rmse.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    cv_rmse_mean.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    \n",
    "    y_pic_pred_result['y_cv_testidx_{}'.format(k)] = pd.Series()\n",
    "    y_pic_pred_result['y_cv_pred_{}'.format(k)] = pd.Series()\n",
    "    \n",
    "    for j in range(len(y_cv_testidx)):\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_testidx_{}'.format(k)] = y_cv_testidx[j]\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_pred_{}'.format(k)] = y_cv_pred[j]            \n",
    "    \n",
    "    #y_pic_pred_result['y_cv_testidx_{}'.format(i)] = pd.Series(y_cv_testidx)\n",
    "    #y_pic_pred_result['y_cv_pred_{}'.format(i)] = pd.Series(y_cv_pred)\n",
    "    k += 1 \n",
    "    \n",
    "    if k % 5 == 0 : \n",
    "        tmp.append(np.mean(cv_rmse_mean))\n",
    "        print(cv_rmse_mean) # per fold rmse value in one cv \n",
    "        print(\"mean : \",np.mean(cv_rmse_mean)) # RMSE mean value per iteration of cv  \n",
    "        del cv_rmse_mean[:]\n",
    "        \n",
    "\n",
    "print(\"total fold mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total cv mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "#model retrain with all train data  \n",
    "neigh.fit(x_train,y_train) # > model train\n",
    "y_pic_test_pred = neigh.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_pic_test_pred_df = pd.DataFrame(columns=['y_pic_test_idx','y_pic_test_pred'])\n",
    "for j in range(len(x_test_idx)):\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_idx'] = x_test_idx[j]\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_pred'] = y_pic_test_pred[j]\n",
    "#y_pic_test_pred_df = pd.DataFrame(y_pic_test_pred,columns=['y_pic_test_pred'])\n",
    "y_pic_pred_result = pd.concat([y_pic_pred_result, y_pic_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "#save csv \n",
    "#y_pic_pred_result.to_csv(result_wdir+'5-alpha-reductase_dltnan_y_pic_pred_result+with_significant_feature.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.1.3 KNN model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train data size : 245 (0.0%)\\n', 'test data size : 28 (0.0%)\\n')\n",
      "each CV RMSE average : \n",
      "[1.20572, 1.25652, 1.25674, 1.2696399999999999, 1.21696, 1.2061, 1.2365400000000002, 1.2889599999999999, 1.246, 1.2221600000000001] \n",
      "VARIANCE of RMSE of every folds : 0.013\n",
      "\n",
      "('total 50 folds RMSE mean : ', 1.2405)\n",
      "('total 10 CVs RMSE mean : ', 1.2405)\n",
      "\n",
      "test RMSE : 0.9768\n"
     ]
    }
   ],
   "source": [
    "#RESULT\n",
    "print(\"train data size : {} ({}%)\\n\".format(len(x_train),round((len(x_train)/len(x)),2)), \"test data size : {} ({}%)\\n\".format(len(x_test),round((len(x_test)/len(x)),2)))\n",
    "print(\"each CV RMSE average : \\n{} \\nVARIANCE of RMSE of every folds : {}\\n\".format(tmp,round(np.var(cv_rmse),4)))\n",
    "\n",
    "print(\"total 50 folds RMSE mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total 10 CVs RMSE mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "# test rseult \n",
    "print(\"\\ntest RMSE : {}\".format(round(np.sqrt(mean_squared_error(y_test,y_pic_test_pred)),4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.1 RF hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bset Parameters set found on GridSearch CV :\n",
      "\n",
      "{'min_samples_split': 5, 'n_estimators': 40, 'max_depth': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "RF = RandomForestRegressor()\n",
    "RF_param_grid = {'n_estimators':[40,60,80,100],\n",
    "              'max_depth':[30,40,50,None],\n",
    "                'min_samples_split':[2,3,4,5,6]} \n",
    "RF_search = GridSearchCV(RF,RF_param_grid,cv=5)\n",
    "RF_search.fit(x_train,y_train)\n",
    "print(\"Bset Parameters set found on GridSearch CV :\\n\")\n",
    "print(RF_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid scores on GridSearchCV :\n",
      "\n",
      "0.454 (+/-0.234) for {'min_samples_split': 2, 'n_estimators': 40, 'max_depth': 30}\n",
      "0.439 (+/-0.227) for {'min_samples_split': 2, 'n_estimators': 60, 'max_depth': 30}\n",
      "0.432 (+/-0.225) for {'min_samples_split': 2, 'n_estimators': 80, 'max_depth': 30}\n",
      "0.456 (+/-0.242) for {'min_samples_split': 2, 'n_estimators': 100, 'max_depth': 30}\n",
      "0.450 (+/-0.223) for {'min_samples_split': 3, 'n_estimators': 40, 'max_depth': 30}\n",
      "0.432 (+/-0.246) for {'min_samples_split': 3, 'n_estimators': 60, 'max_depth': 30}\n",
      "0.439 (+/-0.242) for {'min_samples_split': 3, 'n_estimators': 80, 'max_depth': 30}\n",
      "0.439 (+/-0.225) for {'min_samples_split': 3, 'n_estimators': 100, 'max_depth': 30}\n",
      "0.455 (+/-0.229) for {'min_samples_split': 4, 'n_estimators': 40, 'max_depth': 30}\n",
      "0.438 (+/-0.272) for {'min_samples_split': 4, 'n_estimators': 60, 'max_depth': 30}\n",
      "0.440 (+/-0.214) for {'min_samples_split': 4, 'n_estimators': 80, 'max_depth': 30}\n",
      "0.430 (+/-0.215) for {'min_samples_split': 4, 'n_estimators': 100, 'max_depth': 30}\n",
      "0.439 (+/-0.237) for {'min_samples_split': 5, 'n_estimators': 40, 'max_depth': 30}\n",
      "0.446 (+/-0.217) for {'min_samples_split': 5, 'n_estimators': 60, 'max_depth': 30}\n",
      "0.453 (+/-0.223) for {'min_samples_split': 5, 'n_estimators': 80, 'max_depth': 30}\n",
      "0.462 (+/-0.225) for {'min_samples_split': 5, 'n_estimators': 100, 'max_depth': 30}\n",
      "0.451 (+/-0.204) for {'min_samples_split': 6, 'n_estimators': 40, 'max_depth': 30}\n",
      "0.446 (+/-0.212) for {'min_samples_split': 6, 'n_estimators': 60, 'max_depth': 30}\n",
      "0.455 (+/-0.213) for {'min_samples_split': 6, 'n_estimators': 80, 'max_depth': 30}\n",
      "0.457 (+/-0.229) for {'min_samples_split': 6, 'n_estimators': 100, 'max_depth': 30}\n",
      "0.441 (+/-0.222) for {'min_samples_split': 2, 'n_estimators': 40, 'max_depth': 40}\n",
      "0.441 (+/-0.232) for {'min_samples_split': 2, 'n_estimators': 60, 'max_depth': 40}\n",
      "0.432 (+/-0.271) for {'min_samples_split': 2, 'n_estimators': 80, 'max_depth': 40}\n",
      "0.438 (+/-0.243) for {'min_samples_split': 2, 'n_estimators': 100, 'max_depth': 40}\n",
      "0.428 (+/-0.216) for {'min_samples_split': 3, 'n_estimators': 40, 'max_depth': 40}\n",
      "0.446 (+/-0.199) for {'min_samples_split': 3, 'n_estimators': 60, 'max_depth': 40}\n",
      "0.444 (+/-0.215) for {'min_samples_split': 3, 'n_estimators': 80, 'max_depth': 40}\n",
      "0.448 (+/-0.207) for {'min_samples_split': 3, 'n_estimators': 100, 'max_depth': 40}\n",
      "0.430 (+/-0.258) for {'min_samples_split': 4, 'n_estimators': 40, 'max_depth': 40}\n",
      "0.453 (+/-0.247) for {'min_samples_split': 4, 'n_estimators': 60, 'max_depth': 40}\n",
      "0.438 (+/-0.247) for {'min_samples_split': 4, 'n_estimators': 80, 'max_depth': 40}\n",
      "0.443 (+/-0.227) for {'min_samples_split': 4, 'n_estimators': 100, 'max_depth': 40}\n",
      "0.472 (+/-0.226) for {'min_samples_split': 5, 'n_estimators': 40, 'max_depth': 40}\n",
      "0.448 (+/-0.209) for {'min_samples_split': 5, 'n_estimators': 60, 'max_depth': 40}\n",
      "0.447 (+/-0.217) for {'min_samples_split': 5, 'n_estimators': 80, 'max_depth': 40}\n",
      "0.449 (+/-0.227) for {'min_samples_split': 5, 'n_estimators': 100, 'max_depth': 40}\n",
      "0.455 (+/-0.209) for {'min_samples_split': 6, 'n_estimators': 40, 'max_depth': 40}\n",
      "0.470 (+/-0.218) for {'min_samples_split': 6, 'n_estimators': 60, 'max_depth': 40}\n",
      "0.443 (+/-0.211) for {'min_samples_split': 6, 'n_estimators': 80, 'max_depth': 40}\n",
      "0.456 (+/-0.205) for {'min_samples_split': 6, 'n_estimators': 100, 'max_depth': 40}\n",
      "0.437 (+/-0.222) for {'min_samples_split': 2, 'n_estimators': 40, 'max_depth': 50}\n",
      "0.443 (+/-0.218) for {'min_samples_split': 2, 'n_estimators': 60, 'max_depth': 50}\n",
      "0.427 (+/-0.232) for {'min_samples_split': 2, 'n_estimators': 80, 'max_depth': 50}\n",
      "0.451 (+/-0.244) for {'min_samples_split': 2, 'n_estimators': 100, 'max_depth': 50}\n",
      "0.428 (+/-0.246) for {'min_samples_split': 3, 'n_estimators': 40, 'max_depth': 50}\n",
      "0.423 (+/-0.221) for {'min_samples_split': 3, 'n_estimators': 60, 'max_depth': 50}\n",
      "0.437 (+/-0.201) for {'min_samples_split': 3, 'n_estimators': 80, 'max_depth': 50}\n",
      "0.469 (+/-0.193) for {'min_samples_split': 3, 'n_estimators': 100, 'max_depth': 50}\n",
      "0.433 (+/-0.231) for {'min_samples_split': 4, 'n_estimators': 40, 'max_depth': 50}\n",
      "0.440 (+/-0.246) for {'min_samples_split': 4, 'n_estimators': 60, 'max_depth': 50}\n",
      "0.439 (+/-0.230) for {'min_samples_split': 4, 'n_estimators': 80, 'max_depth': 50}\n",
      "0.439 (+/-0.248) for {'min_samples_split': 4, 'n_estimators': 100, 'max_depth': 50}\n",
      "0.438 (+/-0.187) for {'min_samples_split': 5, 'n_estimators': 40, 'max_depth': 50}\n",
      "0.459 (+/-0.211) for {'min_samples_split': 5, 'n_estimators': 60, 'max_depth': 50}\n",
      "0.437 (+/-0.167) for {'min_samples_split': 5, 'n_estimators': 80, 'max_depth': 50}\n",
      "0.457 (+/-0.243) for {'min_samples_split': 5, 'n_estimators': 100, 'max_depth': 50}\n",
      "0.450 (+/-0.250) for {'min_samples_split': 6, 'n_estimators': 40, 'max_depth': 50}\n",
      "0.455 (+/-0.218) for {'min_samples_split': 6, 'n_estimators': 60, 'max_depth': 50}\n",
      "0.436 (+/-0.232) for {'min_samples_split': 6, 'n_estimators': 80, 'max_depth': 50}\n",
      "0.444 (+/-0.224) for {'min_samples_split': 6, 'n_estimators': 100, 'max_depth': 50}\n",
      "0.449 (+/-0.244) for {'min_samples_split': 2, 'n_estimators': 40, 'max_depth': None}\n",
      "0.449 (+/-0.229) for {'min_samples_split': 2, 'n_estimators': 60, 'max_depth': None}\n",
      "0.444 (+/-0.246) for {'min_samples_split': 2, 'n_estimators': 80, 'max_depth': None}\n",
      "0.450 (+/-0.223) for {'min_samples_split': 2, 'n_estimators': 100, 'max_depth': None}\n",
      "0.453 (+/-0.184) for {'min_samples_split': 3, 'n_estimators': 40, 'max_depth': None}\n",
      "0.438 (+/-0.232) for {'min_samples_split': 3, 'n_estimators': 60, 'max_depth': None}\n",
      "0.440 (+/-0.264) for {'min_samples_split': 3, 'n_estimators': 80, 'max_depth': None}\n",
      "0.452 (+/-0.224) for {'min_samples_split': 3, 'n_estimators': 100, 'max_depth': None}\n",
      "0.437 (+/-0.210) for {'min_samples_split': 4, 'n_estimators': 40, 'max_depth': None}\n",
      "0.450 (+/-0.207) for {'min_samples_split': 4, 'n_estimators': 60, 'max_depth': None}\n",
      "0.459 (+/-0.242) for {'min_samples_split': 4, 'n_estimators': 80, 'max_depth': None}\n",
      "0.461 (+/-0.228) for {'min_samples_split': 4, 'n_estimators': 100, 'max_depth': None}\n",
      "0.428 (+/-0.238) for {'min_samples_split': 5, 'n_estimators': 40, 'max_depth': None}\n",
      "0.445 (+/-0.180) for {'min_samples_split': 5, 'n_estimators': 60, 'max_depth': None}\n",
      "0.446 (+/-0.213) for {'min_samples_split': 5, 'n_estimators': 80, 'max_depth': None}\n",
      "0.441 (+/-0.227) for {'min_samples_split': 5, 'n_estimators': 100, 'max_depth': None}\n",
      "0.441 (+/-0.211) for {'min_samples_split': 6, 'n_estimators': 40, 'max_depth': None}\n",
      "0.468 (+/-0.203) for {'min_samples_split': 6, 'n_estimators': 60, 'max_depth': None}\n",
      "0.439 (+/-0.254) for {'min_samples_split': 6, 'n_estimators': 80, 'max_depth': None}\n",
      "0.443 (+/-0.241) for {'min_samples_split': 6, 'n_estimators': 100, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Grid scores on GridSearchCV :\\n\")\n",
    "\n",
    "means = RF_search.cv_results_['mean_test_score']\n",
    "stds = RF_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, RF_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.2 RF model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_pic50,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_idx = []\n",
    "for row in x_test.index:\n",
    "    x_test_idx.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 0\n",
      "iteration num : 1\n",
      "iteration num : 2\n",
      "iteration num : 3\n",
      "iteration num : 4\n",
      "[1.312, 1.1546, 1.1239, 1.058, 1.3898]\n",
      "('mean : ', 1.2076600000000002)\n",
      "iteration num : 5\n",
      "iteration num : 6\n",
      "iteration num : 7\n",
      "iteration num : 8\n",
      "iteration num : 9\n",
      "[1.2195, 1.2148, 1.3784, 1.281, 0.9819]\n",
      "('mean : ', 1.21512)\n",
      "iteration num : 10\n",
      "iteration num : 11\n",
      "iteration num : 12\n",
      "iteration num : 13\n",
      "iteration num : 14\n",
      "[1.0851, 1.1724, 1.4223, 1.1779, 1.1513]\n",
      "('mean : ', 1.2018)\n",
      "iteration num : 15\n",
      "iteration num : 16\n",
      "iteration num : 17\n",
      "iteration num : 18\n",
      "iteration num : 19\n",
      "[1.1084, 1.145, 1.0885, 1.3173, 1.1422]\n",
      "('mean : ', 1.16028)\n",
      "iteration num : 20\n",
      "iteration num : 21\n",
      "iteration num : 22\n",
      "iteration num : 23\n",
      "iteration num : 24\n",
      "[1.2977, 1.0731, 1.3039, 1.2361, 1.1727]\n",
      "('mean : ', 1.2167)\n",
      "iteration num : 25\n",
      "iteration num : 26\n",
      "iteration num : 27\n",
      "iteration num : 28\n",
      "iteration num : 29\n",
      "[1.3093, 1.2805, 1.2183, 1.2133, 1.0485]\n",
      "('mean : ', 1.2139799999999998)\n",
      "iteration num : 30\n",
      "iteration num : 31\n",
      "iteration num : 32\n",
      "iteration num : 33\n",
      "iteration num : 34\n",
      "[1.2151, 1.2627, 1.1124, 1.1669, 1.0815]\n",
      "('mean : ', 1.16772)\n",
      "iteration num : 35\n",
      "iteration num : 36\n",
      "iteration num : 37\n",
      "iteration num : 38\n",
      "iteration num : 39\n",
      "[1.2347, 1.2414, 1.1771, 1.2174, 1.0732]\n",
      "('mean : ', 1.1887599999999998)\n",
      "iteration num : 40\n",
      "iteration num : 41\n",
      "iteration num : 42\n",
      "iteration num : 43\n",
      "iteration num : 44\n",
      "[1.4042, 1.3664, 1.1279, 0.9863, 1.2591]\n",
      "('mean : ', 1.22878)\n",
      "iteration num : 45\n",
      "iteration num : 46\n",
      "iteration num : 47\n",
      "iteration num : 48\n",
      "iteration num : 49\n",
      "[1.1354, 1.1594, 1.1223, 1.2039, 1.3258]\n",
      "('mean : ', 1.1893600000000002)\n",
      "('total fold mean : ', 1.199)\n",
      "('total cv mean : ', 1.199)\n"
     ]
    }
   ],
   "source": [
    "#fold setting\n",
    "kf = RepeatedKFold(n_splits = 5,n_repeats=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#for numbering k folds\n",
    "k=0\n",
    "cv_rmse = []\n",
    "cv_rmse_mean = []\n",
    "tmp = []\n",
    "\n",
    "#DataFrame generate\n",
    "y_pic_pred_result = pd.DataFrame()\n",
    "y_pic_pred_result['idx'] = pd.Series([i for i in range(len(y))])\n",
    "\n",
    "#model generate\n",
    "##################    using hyperparameter tuning model    ##################    \n",
    "RF = RandomForestRegressor(n_estimators= 40,min_samples_split=5,max_depth=40)\n",
    "\n",
    "#RF without sig, for androgen {'min_samples_split': 5, 'n_estimators': 40, 'max_depth': 40}\n",
    "#RF with sig, for androgen \n",
    "\n",
    "#RF without sig, for aromatase {'min_samples_split': 3, 'n_estimators': 60, 'max_depth': 30}\n",
    "#RF with sig , for aromatase {'min_samples_split': 2, 'n_estimators': 40, 'max_depth': None}\n",
    "#\n",
    "##################    using hyperparameter tuning model    ##################\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    #print(\"iteration num : {}\".format(k))\n",
    "    #print(\"train : \", train_idx, \"\\ntest : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    RF.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = RF.predict(x_cv_test)\n",
    "    cv_rmse.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    cv_rmse_mean.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    \n",
    "    y_pic_pred_result['y_cv_testidx_{}'.format(k)] = pd.Series()\n",
    "    y_pic_pred_result['y_cv_pred_{}'.format(k)] = pd.Series()\n",
    "    \n",
    "    for j in range(len(y_cv_testidx)):\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_testidx_{}'.format(k)] = y_cv_testidx[j]\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_pred_{}'.format(k)] = y_cv_pred[j]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #y_pic_pred_result['y_cv_testidx_{}'.format(i)] = pd.Series(y_cv_testidx)\n",
    "    #y_pic_pred_result['y_cv_pred_{}'.format(i)] = pd.Series(y_cv_pred)\n",
    "    k += 1 \n",
    "    \n",
    "    if k % 5 == 0 : \n",
    "        tmp.append(np.mean(cv_rmse_mean))\n",
    "        print(cv_rmse_mean) # per fold rmse value in one cv \n",
    "        print(\"mean : \",np.mean(cv_rmse_mean)) # RMSE mean value per iteration of cv  \n",
    "        del cv_rmse_mean[:]\n",
    "        \n",
    "\n",
    "print(\"total fold mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total cv mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "#model retrain with all train data  \n",
    "RF.fit(x_train,y_train) # > model train\n",
    "y_pic_test_pred = RF.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_pic_test_pred_df = pd.DataFrame(columns=['y_pic_test_idx','y_pic_test_pred'])\n",
    "for j in range(len(x_test_idx)):\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_idx'] = x_test_idx[j]\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_pred'] = y_pic_test_pred[j]\n",
    "#y_pic_test_pred_df = pd.DataFrame(y_pic_test_pred,columns=['y_pic_test_pred'])\n",
    "y_pic_pred_result = pd.concat([y_pic_pred_result, y_pic_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "#save csv \n",
    "#y_pic_pred_result.to_csv(result_wdir+'5-alpha-reductase_dltnan_y_pic_pred_result+with_significant_feature.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.3 RF model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train data size : 245 (0.0%)\\n', 'test data size : 28 (0.0%)\\n')\n",
      "each CV RMSE average : \n",
      "[1.2076600000000002, 1.21512, 1.2018, 1.16028, 1.2167, 1.2139799999999998, 1.16772, 1.1887599999999998, 1.22878, 1.1893600000000002] \n",
      "VARIANCE of RMSE of every folds : 0.011\n",
      "\n",
      "('total 50 folds RMSE mean : ', 1.199)\n",
      "('total 10 CVs RMSE mean : ', 1.199)\n",
      "\n",
      "test RMSE : 0.8187\n"
     ]
    }
   ],
   "source": [
    "#RESULT\n",
    "print(\"train data size : {} ({}%)\\n\".format(len(x_train),round((len(x_train)/len(x)),2)), \"test data size : {} ({}%)\\n\".format(len(x_test),round((len(x_test)/len(x)),2)))\n",
    "print(\"each CV RMSE average : \\n{} \\nVARIANCE of RMSE of every folds : {}\\n\".format(tmp,round(np.var(cv_rmse),4)))\n",
    "\n",
    "print(\"total 50 folds RMSE mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total 10 CVs RMSE mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "# test rseult \n",
    "print(\"\\ntest RMSE : {}\".format(round(np.sqrt(mean_squared_error(y_test,y_pic_test_pred)),4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.3.1 SVR hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "SVR = SVR()\n",
    "SVR_param_grid = {'kernel':['rbf','linear','poly']} \n",
    "SVR_search = GridSearchCV(SVR,SVR_param_grid,cv=5)\n",
    "SVR_search.fit(x_train,y_train)\n",
    "print(\"Bset Parameters set found on GridSearch CV :\\n\")\n",
    "print(SVR_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grid scores on GridSearchCV :\\n\")\n",
    "\n",
    "means = SVR_search.cv_results_['mean_test_score']\n",
    "stds = SVR_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, SVR_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.3.2 SVR model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold setting\n",
    "kf = RepeatedKFold(n_splits = 5,n_repeats=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#for numbering k folds\n",
    "k=0\n",
    "cv_rmse = []\n",
    "cv_rmse_mean = []\n",
    "tmp = []\n",
    "\n",
    "#DataFrame generate\n",
    "y_pic_pred_result = pd.DataFrame()\n",
    "y_pic_pred_result['idx'] = pd.Series([i for i in range(len(y))])\n",
    "\n",
    "#model generate\n",
    "##################    using hyperparameter tuning model    ##################    \n",
    "SVR = SVR(kernel='rbf')\n",
    "##################    using hyperparameter tuning model    ##################\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    print(\"iteration num : {}\".format(k))\n",
    "    #print(\"train : \", train_idx, \"\\ntest : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    SVR.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = SVR.predict(x_cv_test)\n",
    "    cv_rmse.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    cv_rmse_mean.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    \n",
    "    y_pic_pred_result['y_cv_testidx_{}'.format(k)] = pd.Series()\n",
    "    y_pic_pred_result['y_cv_pred_{}'.format(k)] = pd.Series()\n",
    "    \n",
    "    for j in range(len(y_cv_testidx)):\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_testidx_{}'.format(k)] = y_cv_testidx[j]\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_pred_{}'.format(k)] = y_cv_pred[j]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #y_pic_pred_result['y_cv_testidx_{}'.format(i)] = pd.Series(y_cv_testidx)\n",
    "    #y_pic_pred_result['y_cv_pred_{}'.format(i)] = pd.Series(y_cv_pred)\n",
    "    k += 1 \n",
    "    \n",
    "    if k % 5 == 0 : \n",
    "        tmp.append(np.mean(cv_rmse_mean))\n",
    "        print(cv_rmse_mean) # per fold rmse value in one cv \n",
    "        print(\"mean : \",np.mean(cv_rmse_mean)) # RMSE mean value per iteration of cv  \n",
    "        del cv_rmse_mean[:]\n",
    "        \n",
    "\n",
    "print(\"total fold mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total cv mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "#model retrain with all train data  \n",
    "SVR.fit(x_train,y_train) # > model train\n",
    "y_pic_test_pred = SVR.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_pic_test_pred_df = pd.DataFrame(columns=['y_pic_test_idx','y_pic_test_pred'])\n",
    "for j in range(len(x_test_idx)):\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_idx'] = x_test_idx[j]\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_pred'] = y_pic_test_pred[j]\n",
    "#y_pic_test_pred_df = pd.DataFrame(y_pic_test_pred,columns=['y_pic_test_pred'])\n",
    "y_pic_pred_result = pd.concat([y_pic_pred_result, y_pic_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "#save csv \n",
    "#y_pic_pred_result.to_csv(result_wdir+'5-alpha-reductase_dltnan_y_pic_pred_result+with_significant_feature.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.3.3 SVR model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULT\n",
    "print(\"train data size : {} ({}%)\\n\".format(len(x_train),round((len(x_train)/len(x)),2)), \"test data size : {} ({}%)\\n\".format(len(x_test),round((len(x_test)/len(x)),2)))\n",
    "print(\"each CV RMSE average : \\n{} \\nVARIANCE of RMSE of every folds : {}\\n\".format(tmp,round(np.var(cv_rmse),4)))\n",
    "\n",
    "print(\"total 50 folds RMSE mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total 10 CVs RMSE mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "# test rseult \n",
    "print(\"\\ntest RMSE : {}\".format(round(np.sqrt(mean_squared_error(y_test,y_pic_test_pred)),4)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect as _GetMorganFingerprintAsBitVect, GetMorganFingerprint as _GetMorganFingerprint\n",
    "from bioalerts import LoadMolecules, Alerts, FPCalculator \n",
    "from rdkit import Chem \n",
    "\n",
    "# >>> _GetMorganFingerprint #Returns a Morgan fingerprint for a molecule\n",
    "# >>> _GetMorganFingerprintAsBitVect  #Returns a Morgan fingerprint for a molecule as a bit vector\n",
    "\n",
    "molecules = LoadMolecules.LoadMolecules(\"./tutorial/datasets/5AR.smi\",name_field=None)\n",
    "molecules.ReadMolecules() \n",
    "stride = int(len(molecules.mols)*0.9)\n",
    "training = molecules.mols[0:stride]\n",
    "test = molecules.mols[stride:len(molecules.mols)]\n",
    "print (len(molecules.mols), len(test), len(training))\n",
    "\n",
    "radii = [2,3,4,5,6]\n",
    "\n",
    "\n",
    "def extract_substructure_information(radii,mols):\n",
    "    substructure_dictionary = {}\n",
    "    for i,m in enumerate(mols):\n",
    "        info = {}\n",
    "        fp = _GetMorganFingerprint(m,max(radii),bitInfo=info)\n",
    "        for k,v in info.items():\n",
    "            if v[0][1] in radii:\n",
    "                if k in substructure_dictionary.keys():\n",
    "                    substructure_dictionary[k].append(i)\n",
    "                else : \n",
    "                    substructure_dictionary.update({k:[i]})\n",
    "    return substructure_dictionary\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
