{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnull_idx = []\\ndf_std = df['Standard Value']\\ndf_null = df_std.isnull()\\nfor i in range(len(df_null)):\\n    if df_null.iloc[i] == True: \\n        null_idx.append(i)\\nnull_idx\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "wdir =  'C:/jupyter_devel/kist-europe/QSAR/AOP_data/'\n",
    "csv = '5-alpha-reductase-maccs-remcols-stdval-dltnan.csv'\n",
    "#csv = '5-alpha-reductase-maccs-remcols-stdval-dlt-outlier.csv'\n",
    "\n",
    "#save dir for model result\n",
    "result_wdir = 'C:/jupyter_devel/kist-europe/QSAR/AOP_data/model_result/'\n",
    "\n",
    "df = pd.read_csv(wdir+csv)\n",
    "\n",
    "# check which compound is NaN Standard Value \n",
    "\"\"\"\n",
    "null_idx = []\n",
    "df_std = df['Standard Value']\n",
    "df_null = df_std.isnull()\n",
    "for i in range(len(df_null)):\n",
    "    if df_null.iloc[i] == True: \n",
    "        null_idx.append(i)\n",
    "null_idx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0) #axis=0 means forward rows \n",
    "\n",
    "y = df['Standard Value']\n",
    "x = df.drop(['Molecule','Standard Value'],axis=1) #axis=1 means forward cols\n",
    "\n",
    "#save data with removing NaN values\n",
    "#df.to_csv(wdir+'5-alpha-reductase-maccs-remcols-stdval-dltnan.csv'.format(i),index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping (datasize,x, y):\n",
    "    #Random sampling with duplication\n",
    "    train = []\n",
    "    for i in range(datasize):\n",
    "        train.append(random.randrange(datasize))\n",
    "    \n",
    "    #Find indices not sampled\n",
    "    test = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if i not in train:\n",
    "            test.append(i)\n",
    "    \n",
    "    #Subsetting dataframe from sampled and unsampled data\n",
    "    train_x = x.iloc[train]\n",
    "    train_y = y.iloc[train]\n",
    "    \n",
    "    test_x = x.iloc[test]\n",
    "    test_y = y.iloc[test]\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 0 _k folds      for getting knowledge that which data is involving within certain fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for modern stdval prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fold setting\n",
    "kf = RepeatedKFold(n_splits = 5,n_repeats=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "#>>> <sklearn.model_selection._split.RepeatedKFold at 0x2939c6ffcc8>\n",
    "\n",
    "#for numbering k folds\n",
    "i=1\n",
    "cv_mean = []\n",
    "\n",
    "#DataFrame generate\n",
    "y_pred_result = pd.DataFrame()\n",
    "\n",
    "#model generate\n",
    "neigh = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    print(\"train : \", train_idx, \"test : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    neigh.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = neigh.predict(x_cv_test)\n",
    "    cv_mse.append(mean_squared_error(y_cv_test,y_cv_pred))\n",
    "    \n",
    "    y_pred_result['y_cv_testidx_{}'.format(i)] = y_cv_testidx\n",
    "    y_pred_result['y_cv_pred_{}'.format(i)] = y_cv_pred\n",
    "    i += 1 \n",
    "    if i % 5 == 0 : \n",
    "        print(cv_mean)\n",
    "        \n",
    "\n",
    "#model retrain with all train data  \n",
    "neigh.fit(x_train,y_train) # > model train\n",
    "y_test_pred = neigh.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_test_pred_df = pd.DataFrame(y_test_pred,columns=['y_pred_test'])\n",
    "y_pred_result = pd.concat([y_pred_result, y_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "#y_pred_result.to_csv(result_wdir+'y_pred_result.csv'.format(i),index=True)\n",
    "y_pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_v0 = mean_squared_error(y_test,y_test_pred)\n",
    "MSE_v0\n",
    "RMSE_v0 = np.sqrt(MSE_v0)\n",
    "RMSE_v0\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} \".format(MSE_v0,RMSE_v0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for log scale stdval prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(y)\n",
    "y_log\n",
    "\n",
    "#for saving values\n",
    "#y_log.to_csv(result_wdir+'LOG(Standard_Value).csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_log,test_size = test_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fold setting\n",
    "kf = KFold(n_splits = 5)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#for numbering k folds\n",
    "i=1\n",
    "\n",
    "#DataFrame generate\n",
    "y_log_pred_result = pd.DataFrame()\n",
    "\n",
    "#model generate\n",
    "neigh = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    print(\"train : \", train_idx, \"test : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    neigh.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = neigh.predict(x_cv_test)\n",
    "    y_log_pred_result['y_cv_testidx_{}'.format(i)] = y_cv_testidx\n",
    "    y_log_pred_result['y_cv_pred_{}'.format(i)] = y_cv_pred\n",
    "    i += 1 \n",
    "\n",
    "#model retrain with all train data  \n",
    "neigh.fit(x_train,y_train) # > model train\n",
    "y_log_test_pred = neigh.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_log_test_pred_df = pd.DataFrame(y_log_test_pred,columns=['y_log_test_pred'])\n",
    "y_log_pred_result = pd.concat([y_log_pred_result, y_log_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "y_log_pred_result.to_csv(result_wdir+'y_log_pred_result.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_v0_ = mean_squared_error(y_test,y_log_test_pred)\n",
    "MSE_v0_\n",
    "RMSE_v0_ = np.sqrt(MSE_v0_)\n",
    "RMSE_v0_\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} \".format(MSE_v0_,RMSE_v0_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for pIC50 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chon0\\Anaconda3\\envs\\develroom\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#pic50 = log(10^9/ic50) = 9 - log10(ic50)\n",
    "\n",
    "y_pic50 = 9 - np.log10(y)\n",
    "y_pic50\n",
    "\n",
    "#for saving values\n",
    "y_pic50.to_csv(result_wdir+'5-alpha-reductase_dltnan_PIC50_value.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_pic50,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 86,\n",
       " 177,\n",
       " 60,\n",
       " 138,\n",
       " 186,\n",
       " 190,\n",
       " 188,\n",
       " 152,\n",
       " 184,\n",
       " 113,\n",
       " 172,\n",
       " 193,\n",
       " 169,\n",
       " 203,\n",
       " 134,\n",
       " 121,\n",
       " 258,\n",
       " 126,\n",
       " 260,\n",
       " 146,\n",
       " 73,\n",
       " 128,\n",
       " 77,\n",
       " 269,\n",
       " 49,\n",
       " 183,\n",
       " 25]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_idx = []\n",
    "for row in x_test.index:\n",
    "    x_test_idx.append(row)\n",
    "    \n",
    "x_test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 0\n",
      "train :  [  1   2   5   6   7   8   9  10  13  16  17  18  19  20  21  22  23  24\n",
      "  25  26  27  28  29  31  33  34  36  37  38  40  41  42  43  44  45  47\n",
      "  48  49  51  53  54  55  56  57  58  59  60  61  63  64  66  67  69  70\n",
      "  71  72  75  76  77  78  80  81  83  84  85  86  87  88  89  91  92  93\n",
      "  94  95  96  97  98  99 100 101 102 103 104 105 106 110 111 112 113 115\n",
      " 117 118 120 122 123 124 125 128 129 130 132 133 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177\n",
      " 178 179 181 182 183 184 185 187 188 189 191 192 193 195 196 197 198 199\n",
      " 201 202 203 205 206 207 208 209 212 213 214 216 218 219 220 221 222 223\n",
      " 224 225 226 228 229 231 232 233 234 235 236 237 238 241 243 244 245 247\n",
      " 248 249] \n",
      "test :  [  0   3   4  11  12  14  15  30  32  35  39  46  50  52  62  65  68  73\n",
      "  74  79  82  90 107 108 109 114 116 119 121 126 127 131 134 150 180 186\n",
      " 190 194 200 204 210 211 215 217 227 230 239 240 242 246]\n",
      "iteration num : 1\n",
      "train :  [  0   1   2   3   4   5   6   7   9  10  11  12  14  15  16  17  18  20\n",
      "  22  23  24  25  27  28  29  30  31  32  33  34  35  37  38  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  58  60  61  62  64  65\n",
      "  66  68  70  71  72  73  74  75  76  77  79  80  81  82  83  84  85  86\n",
      "  89  90  91  92  93  94  97  98  99 100 101 103 105 106 107 108 109 110\n",
      " 111 112 114 115 116 117 119 121 123 124 125 126 127 128 129 130 131 132\n",
      " 133 134 135 136 137 138 139 140 141 143 144 145 146 147 149 150 151 153\n",
      " 154 155 156 157 158 159 160 161 162 163 164 165 166 167 169 170 171 173\n",
      " 174 175 177 178 180 181 184 185 186 187 190 191 192 193 194 195 200 202\n",
      " 204 205 207 208 209 210 211 212 213 214 215 216 217 219 221 223 224 226\n",
      " 227 228 229 230 231 233 234 235 236 237 238 239 240 241 242 243 245 246\n",
      " 248 249] \n",
      "test :  [  8  13  19  21  26  36  54  55  56  57  59  63  67  69  78  87  88  95\n",
      "  96 102 104 113 118 120 122 142 148 152 168 172 176 179 182 183 188 189\n",
      " 196 197 198 199 201 203 206 218 220 222 225 232 244 247]\n",
      "iteration num : 2\n",
      "train :  [  0   1   2   3   4   6   7   8   9  10  11  12  13  14  15  17  19  20\n",
      "  21  22  23  25  26  27  28  29  30  31  32  34  35  36  37  38  39  40\n",
      "  41  43  44  46  47  48  50  51  52  53  54  55  56  57  58  59  60  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  78  79  80  81  82  83\n",
      "  84  86  87  88  90  91  92  93  94  95  96  97 101 102 103 104 105 106\n",
      " 107 108 109 110 112 113 114 115 116 117 118 119 120 121 122 124 126 127\n",
      " 129 130 131 132 133 134 135 136 137 138 141 142 144 145 147 148 150 152\n",
      " 154 155 157 159 160 161 163 164 166 167 168 170 171 172 175 176 178 179\n",
      " 180 181 182 183 184 185 186 188 189 190 191 193 194 196 197 198 199 200\n",
      " 201 203 204 206 208 209 210 211 214 215 216 217 218 219 220 221 222 223\n",
      " 224 225 226 227 228 230 232 233 234 235 236 238 239 240 241 242 243 244\n",
      " 246 247] \n",
      "test :  [  5  16  18  24  33  42  45  49  61  75  76  77  85  89  98  99 100 111\n",
      " 123 125 128 139 140 143 146 149 151 153 156 158 162 165 169 173 174 177\n",
      " 187 192 195 202 205 207 212 213 229 231 237 245 248 249]\n",
      "iteration num : 3\n",
      "train :  [  0   3   4   5   6   7   8  10  11  12  13  14  15  16  18  19  20  21\n",
      "  23  24  26  29  30  31  32  33  35  36  37  39  40  41  42  45  46  47\n",
      "  49  50  51  52  53  54  55  56  57  59  60  61  62  63  65  66  67  68\n",
      "  69  72  73  74  75  76  77  78  79  81  82  85  87  88  89  90  91  93\n",
      "  95  96  98  99 100 101 102 104 105 106 107 108 109 110 111 113 114 116\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 131 134 135 136 137 139\n",
      " 140 141 142 143 146 148 149 150 151 152 153 154 156 157 158 161 162 163\n",
      " 165 167 168 169 170 172 173 174 176 177 178 179 180 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 209 210 211 212 213 215 216 217 218 220 221 222 225 226 227\n",
      " 228 229 230 231 232 233 234 235 236 237 238 239 240 242 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  1   2   9  17  22  25  27  28  34  38  43  44  48  58  64  70  71  80\n",
      "  83  84  86  92  94  97 103 112 115 117 130 132 133 138 144 145 147 155\n",
      " 159 160 164 166 171 175 181 208 214 219 223 224 241 243]\n",
      "iteration num : 4\n",
      "train :  [  0   1   2   3   4   5   8   9  11  12  13  14  15  16  17  18  19  21\n",
      "  22  24  25  26  27  28  30  32  33  34  35  36  38  39  42  43  44  45\n",
      "  46  48  49  50  52  54  55  56  57  58  59  61  62  63  64  65  67  68\n",
      "  69  70  71  73  74  75  76  77  78  79  80  82  83  84  85  86  87  88\n",
      "  89  90  92  94  95  96  97  98  99 100 102 103 104 107 108 109 111 112\n",
      " 113 114 115 116 117 118 119 120 121 122 123 125 126 127 128 130 131 132\n",
      " 133 134 138 139 140 142 143 144 145 146 147 148 149 150 151 152 153 155\n",
      " 156 158 159 160 162 164 165 166 168 169 171 172 173 174 175 176 177 179\n",
      " 180 181 182 183 186 187 188 189 190 192 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206 207 208 210 211 212 213 214 215 217 218 219 220 222\n",
      " 223 224 225 227 229 230 231 232 237 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  6   7  10  20  23  29  31  37  40  41  47  51  53  60  66  72  81  91\n",
      "  93 101 105 106 110 124 129 135 136 137 141 154 157 161 163 167 170 178\n",
      " 184 185 191 193 209 216 221 226 228 233 234 235 236 238]\n",
      "[0.7384, 0.6462, 0.7095, 0.7976, 0.8657]\n",
      "mean :  0.75148\n",
      "iteration num : 5\n",
      "train :  [  0   1   2   3   4   5   6   7   9  10  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  25  27  29  30  33  35  36  37  38  39  41  43  45  46\n",
      "  47  48  49  50  51  53  55  56  57  58  59  60  62  64  65  66  67  68\n",
      "  69  72  73  74  75  76  77  79  80  82  83  85  87  88  89  91  92  93\n",
      "  94  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114\n",
      " 115 116 118 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 138 140 141 142 143 144 145 147 148 149 150 151 152 153 158 159 160\n",
      " 162 165 166 167 168 169 171 172 173 175 176 178 179 180 182 183 184 185\n",
      " 186 187 188 189 190 191 192 193 194 196 197 198 199 200 202 203 205 206\n",
      " 207 208 210 211 212 213 214 215 216 217 218 219 220 222 223 224 225 226\n",
      " 227 228 229 230 231 232 234 236 237 238 239 240 241 242 243 244 245 246\n",
      " 248 249] \n",
      "test :  [  8  11  12  26  28  31  32  34  40  42  44  52  54  61  63  70  71  78\n",
      "  81  84  86  90  95  96  97 117 119 120 137 139 146 154 155 156 157 161\n",
      " 163 164 170 174 177 181 195 201 204 209 221 233 235 247]\n",
      "iteration num : 6\n",
      "train :  [  0   1   2   4   6   7   8  10  11  12  13  14  15  16  18  19  20  22\n",
      "  24  25  26  27  28  31  32  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  47  48  49  52  53  54  55  56  59  60  61  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  81  82  84  86  87  88  89\n",
      "  90  92  93  95  96  97  98  99 101 102 103 104 105 107 109 114 115 116\n",
      " 117 119 120 121 122 124 125 127 128 129 130 131 133 134 136 137 138 139\n",
      " 140 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 159\n",
      " 160 161 163 164 165 166 168 169 170 171 173 174 175 176 177 178 179 180\n",
      " 181 182 184 185 186 187 188 189 190 191 193 194 195 196 197 199 200 201\n",
      " 202 203 204 205 206 208 209 210 211 212 213 215 216 217 218 219 220 221\n",
      " 224 225 227 229 230 231 232 233 234 235 237 239 240 241 242 244 246 247\n",
      " 248 249] \n",
      "test :  [  3   5   9  17  21  23  29  30  33  46  50  51  57  58  62  80  83  85\n",
      "  91  94 100 106 108 110 111 112 113 118 123 126 132 135 141 158 162 167\n",
      " 172 183 192 198 207 214 222 223 226 228 236 238 243 245]\n",
      "iteration num : 7\n",
      "train :  [  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "  58  59  60  61  62  63  64  65  68  69  70  71  72  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  94  95  96  97  99\n",
      " 100 103 104 105 106 108 110 111 112 113 115 116 117 118 119 120 122 123\n",
      " 124 126 129 131 132 134 135 137 139 141 146 148 149 151 152 153 154 155\n",
      " 156 157 158 160 161 162 163 164 165 166 167 168 170 172 173 174 175 176\n",
      " 177 178 179 180 181 182 183 185 187 188 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 204 207 208 209 210 214 215 220 221 222 223 226 227\n",
      " 228 229 230 232 233 234 235 236 237 238 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  7  24  27  45  66  67  73  92  93  98 101 102 107 109 114 121 125 127\n",
      " 128 130 133 136 138 140 142 143 144 145 147 150 159 169 171 184 186 189\n",
      " 203 205 206 211 212 213 216 217 218 219 224 225 231 239]\n",
      "iteration num : 8\n",
      "train :  [  1   2   3   4   5   7   8   9  11  12  13  16  17  18  21  23  24  26\n",
      "  27  28  29  30  31  32  33  34  39  40  41  42  43  44  45  46  50  51\n",
      "  52  53  54  55  57  58  60  61  62  63  65  66  67  68  70  71  73  77\n",
      "  78  79  80  81  83  84  85  86  87  88  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 106 107 108 109 110 111 112 113 114 116 117 118\n",
      " 119 120 121 123 124 125 126 127 128 129 130 131 132 133 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 150 151 152 153 154 155 156 157 158\n",
      " 159 161 162 163 164 165 166 167 168 169 170 171 172 174 177 178 179 180\n",
      " 181 182 183 184 185 186 188 189 192 193 195 196 198 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 221 222 223\n",
      " 224 225 226 227 228 229 231 233 235 236 237 238 239 240 241 243 244 245\n",
      " 246 247] \n",
      "test :  [  0   6  10  14  15  19  20  22  25  35  36  37  38  47  48  49  56  59\n",
      "  64  69  72  74  75  76  82  89 104 105 115 122 134 148 149 160 173 175\n",
      " 176 187 190 191 194 197 199 220 230 232 234 242 248 249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 9\n",
      "train :  [  0   3   5   6   7   8   9  10  11  12  14  15  17  19  20  21  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  40  42  44\n",
      "  45  46  47  48  49  50  51  52  54  56  57  58  59  61  62  63  64  66\n",
      "  67  69  70  71  72  73  74  75  76  78  80  81  82  83  84  85  86  89\n",
      "  90  91  92  93  94  95  96  97  98 100 101 102 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 117 118 119 120 121 122 123 125 126 127 128 130\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 154 155 156 157 158 159 160 161 162 163 164 167 169 170 171 172 173\n",
      " 174 175 176 177 181 183 184 186 187 189 190 191 192 194 195 197 198 199\n",
      " 201 203 204 205 206 207 209 211 212 213 214 216 217 218 219 220 221 222\n",
      " 223 224 225 226 228 230 231 232 233 234 235 236 238 239 242 243 245 247\n",
      " 248 249] \n",
      "test :  [  1   2   4  13  16  18  39  41  43  53  55  60  65  68  77  79  87  88\n",
      "  99 103 116 124 129 131 151 152 153 165 166 168 178 179 180 182 185 188\n",
      " 193 196 200 202 208 210 215 227 229 237 240 241 244 246]\n",
      "[0.7208, 0.6968, 0.7407, 0.8977, 0.8619]\n",
      "mean :  0.7835799999999999\n",
      "iteration num : 10\n",
      "train :  [  0   1   2   4   6   7   8  10  12  13  14  16  17  18  19  20  21  22\n",
      "  23  24  25  26  27  29  30  31  32  34  35  36  37  38  39  40  42  45\n",
      "  46  47  49  50  51  52  53  56  57  60  61  64  65  66  67  68  69  71\n",
      "  72  73  74  75  76  77  78  80  81  82  83  84  85  86  87  88  90  91\n",
      "  92  93  94  95  96  98 100 101 104 105 106 107 108 109 111 112 113 114\n",
      " 115 117 119 120 121 122 123 124 125 127 128 130 131 132 133 134 135 136\n",
      " 137 139 140 142 143 144 145 146 147 148 149 150 151 152 154 155 156 158\n",
      " 159 160 161 162 163 164 165 166 168 171 172 174 175 176 178 179 180 183\n",
      " 184 185 186 187 188 190 191 192 193 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206 208 210 211 213 214 216 217 218 219 220 221 222 223 224 225\n",
      " 226 227 228 230 231 232 233 234 236 237 239 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  3   5   9  11  15  28  33  41  43  44  48  54  55  58  59  62  63  70\n",
      "  79  89  97  99 102 103 110 116 118 126 129 138 141 153 157 167 169 170\n",
      " 173 177 181 182 189 194 207 209 212 215 229 235 238 240]\n",
      "iteration num : 11\n",
      "train :  [  0   1   2   3   4   5   6   7   9  11  13  14  15  16  17  18  20  21\n",
      "  23  24  25  28  31  33  35  36  37  38  40  41  42  43  44  45  48  49\n",
      "  51  52  54  55  57  58  59  60  61  62  63  64  65  67  68  69  70  71\n",
      "  72  73  74  76  79  80  82  83  85  86  87  88  89  90  91  92  93  94\n",
      "  96  97  98  99 100 101 102 103 104 106 107 109 110 111 112 113 114 115\n",
      " 116 117 118 119 121 122 123 124 126 128 129 130 132 133 134 135 138 139\n",
      " 140 141 142 143 144 145 147 149 150 151 152 153 154 156 157 159 160 163\n",
      " 164 165 167 168 169 170 171 172 173 174 175 177 179 180 181 182 184 185\n",
      " 186 187 188 189 190 191 192 193 194 196 197 198 199 200 202 203 204 205\n",
      " 206 207 209 210 211 212 213 214 215 216 217 218 220 221 222 225 226 227\n",
      " 228 229 230 231 232 233 235 236 237 238 239 240 241 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  8  10  12  19  22  26  27  29  30  32  34  39  46  47  50  53  56  66\n",
      "  75  77  78  81  84  95 105 108 120 125 127 131 136 137 146 148 155 158\n",
      " 161 162 166 176 178 183 195 201 208 219 223 224 234 242]\n",
      "iteration num : 12\n",
      "train :  [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18  19\n",
      "  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  50  53  54  55  56  57  58  59\n",
      "  62  63  64  66  69  70  71  72  75  76  77  78  79  80  81  82  83  84\n",
      "  85  88  89  91  93  94  95  96  97  98  99 100 101 102 103 104 105 107\n",
      " 108 110 111 112 113 114 116 117 118 119 120 121 122 123 125 126 127 128\n",
      " 129 130 131 132 133 135 136 137 138 140 141 142 145 146 147 148 150 151\n",
      " 152 153 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 173 174 176 177 178 180 181 182 183 186 189 191 192 194 195 196 198\n",
      " 199 200 201 202 203 204 207 208 209 212 213 215 216 217 218 219 223 224\n",
      " 225 227 228 229 231 232 233 234 235 236 237 238 239 240 241 242 244 245\n",
      " 246 247] \n",
      "test :  [  2  17  23  31  51  52  60  61  65  67  68  73  74  86  87  90  92 106\n",
      " 109 115 124 134 139 143 144 149 154 172 175 179 184 185 187 188 190 193\n",
      " 197 205 206 210 211 214 220 221 222 226 230 243 248 249]\n",
      "iteration num : 13\n",
      "train :  [  0   1   2   3   4   5   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  41  43  44  46  47  48  49  50  51  52  53  54  55  56  58  59  60  61\n",
      "  62  63  65  66  67  68  69  70  73  74  75  77  78  79  81  82  84  85\n",
      "  86  87  89  90  92  93  95  97  98  99 102 103 105 106 107 108 109 110\n",
      " 113 114 115 116 118 119 120 124 125 126 127 129 130 131 132 134 136 137\n",
      " 138 139 140 141 143 144 146 147 148 149 151 152 153 154 155 157 158 161\n",
      " 162 164 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 195 197 200 201 202\n",
      " 205 206 207 208 209 210 211 212 213 214 215 217 219 220 221 222 223 224\n",
      " 225 226 229 230 231 233 234 235 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  6   7  24  25  40  42  45  57  64  71  72  76  80  83  88  91  94  96\n",
      " 100 101 104 111 112 117 121 122 123 128 133 135 142 145 150 156 159 160\n",
      " 163 171 196 198 199 203 204 216 218 227 228 232 236 237]\n",
      "iteration num : 14\n",
      "train :  [  2   3   5   6   7   8   9  10  11  12  15  17  19  22  23  24  25  26\n",
      "  27  28  29  30  31  32  33  34  39  40  41  42  43  44  45  46  47  48\n",
      "  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67\n",
      "  68  70  71  72  73  74  75  76  77  78  79  80  81  83  84  86  87  88\n",
      "  89  90  91  92  94  95  96  97  99 100 101 102 103 104 105 106 108 109\n",
      " 110 111 112 115 116 117 118 120 121 122 123 124 125 126 127 128 129 131\n",
      " 133 134 135 136 137 138 139 141 142 143 144 145 146 148 149 150 153 154\n",
      " 155 156 157 158 159 160 161 162 163 166 167 169 170 171 172 173 175 176\n",
      " 177 178 179 181 182 183 184 185 187 188 189 190 193 194 195 196 197 198\n",
      " 199 201 203 204 205 206 207 208 209 210 211 212 214 215 216 218 219 220\n",
      " 221 222 223 224 226 227 228 229 230 232 234 235 236 237 238 240 242 243\n",
      " 248 249] \n",
      "test :  [  0   1   4  13  14  16  18  20  21  35  36  37  38  49  69  82  85  93\n",
      "  98 107 113 114 119 130 132 140 147 151 152 164 165 168 174 180 186 191\n",
      " 192 200 202 213 217 225 231 233 239 241 244 245 246 247]\n",
      "[0.7862, 0.984, 0.5584, 0.7225, 0.6877]\n",
      "mean :  0.74776\n",
      "iteration num : 15\n",
      "train :  [  0   1   2   3   4   5   6   7   9  13  14  17  18  19  20  21  22  23\n",
      "  24  26  27  28  29  30  31  32  34  35  36  37  38  39  41  42  44  45\n",
      "  46  47  48  49  51  53  54  55  56  57  59  61  62  64  65  67  68  70\n",
      "  71  72  73  74  75  78  79  80  81  83  84  85  86  87  88  89  90  91\n",
      "  92  93  95  97  98  99 100 101 102 104 106 107 108 109 110 111 112 113\n",
      " 114 115 116 117 118 120 121 122 123 124 125 126 127 128 130 131 132 135\n",
      " 136 137 138 139 140 142 143 145 146 147 148 149 150 153 154 156 157 158\n",
      " 159 160 161 162 163 166 168 170 171 172 173 175 176 177 178 179 181 182\n",
      " 183 185 186 188 189 190 191 192 193 195 196 197 198 199 200 201 204 205\n",
      " 206 207 208 209 210 211 213 214 215 216 217 219 220 222 223 224 225 226\n",
      " 227 228 229 230 231 232 233 234 236 237 238 240 241 242 243 244 245 246\n",
      " 248 249] \n",
      "test :  [  8  10  11  12  15  16  25  33  40  43  50  52  58  60  63  66  69  76\n",
      "  77  82  94  96 103 105 119 129 133 134 141 144 151 152 155 164 165 167\n",
      " 169 174 180 184 187 194 202 203 212 218 221 235 239 247]\n",
      "iteration num : 16\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  18  19\n",
      "  21  22  23  25  26  28  29  30  31  32  33  34  36  37  38  39  40  42\n",
      "  43  44  45  46  47  49  50  52  54  55  56  57  58  60  61  62  63  64\n",
      "  66  68  69  70  72  73  74  75  76  77  78  79  80  81  82  83  84  85\n",
      "  86  87  88  90  91  94  95  96  97  98 100 101 102 103 104 105 106 107\n",
      " 108 109 110 112 113 114 115 116 117 118 119 120 121 123 125 126 128 129\n",
      " 130 131 132 133 134 135 137 138 139 140 141 142 143 144 145 146 147 150\n",
      " 151 152 153 155 157 158 159 162 163 164 165 167 168 169 170 171 172 173\n",
      " 174 176 178 179 180 181 182 183 184 187 189 190 191 192 193 194 198 200\n",
      " 201 202 203 204 205 206 207 209 210 211 212 213 215 216 217 218 219 220\n",
      " 221 224 225 226 227 228 231 232 233 235 236 237 238 239 242 243 246 247\n",
      " 248 249] \n",
      "test :  [ 13  14  20  24  27  35  41  48  51  53  59  65  67  71  89  92  93  99\n",
      " 111 122 124 127 136 148 149 154 156 160 161 166 175 177 185 186 188 195\n",
      " 196 197 199 208 214 222 223 229 230 234 240 241 244 245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 17\n",
      "train :  [  1   2   3   6   7   8   9  10  11  12  13  14  15  16  17  20  21  22\n",
      "  23  24  25  26  27  28  29  30  31  32  33  35  36  37  38  39  40  41\n",
      "  43  44  46  47  48  49  50  51  52  53  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  77  78  80  82  83  84\n",
      "  86  87  88  89  90  92  93  94  96  97  99 100 103 105 106 108 109 111\n",
      " 113 114 115 116 117 118 119 120 122 123 124 125 127 128 129 130 132 133\n",
      " 134 135 136 141 142 144 146 147 148 149 150 151 152 153 154 155 156 157\n",
      " 159 160 161 162 163 164 165 166 167 168 169 170 173 174 175 176 177 178\n",
      " 179 180 181 183 184 185 186 187 188 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 207 208 209 210 212 214 216 217 218 220 221 222 223\n",
      " 224 225 227 228 229 230 231 233 234 235 238 239 240 241 242 244 245 246\n",
      " 247 248] \n",
      "test :  [  0   4   5  18  19  34  42  45  54  55  57  79  81  85  91  95  98 101\n",
      " 102 104 107 110 112 121 126 131 137 138 139 140 143 145 158 171 172 182\n",
      " 189 204 205 206 211 213 215 219 226 232 236 237 243 249]\n",
      "iteration num : 18\n",
      "train :  [  0   3   4   5   7   8  10  11  12  13  14  15  16  18  19  20  21  23\n",
      "  24  25  27  28  29  30  32  33  34  35  39  40  41  42  43  45  47  48\n",
      "  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66\n",
      "  67  68  69  70  71  72  75  76  77  78  79  81  82  83  84  85  87  89\n",
      "  91  92  93  94  95  96  98  99 101 102 103 104 105 107 109 110 111 112\n",
      " 113 116 119 121 122 124 125 126 127 128 129 130 131 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 147 148 149 151 152 153 154 155 156 158\n",
      " 159 160 161 162 163 164 165 166 167 169 170 171 172 174 175 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 193 194 195 196 197 199 200\n",
      " 202 203 204 205 206 208 211 212 213 214 215 217 218 219 221 222 223 224\n",
      " 225 226 227 229 230 231 232 233 234 235 236 237 239 240 241 243 244 245\n",
      " 247 249] \n",
      "test :  [  1   2   6   9  17  22  26  31  36  37  38  44  46  73  74  80  86  88\n",
      "  90  97 100 106 108 114 115 117 118 120 123 132 146 150 157 168 173 176\n",
      " 191 192 198 201 207 209 210 216 220 228 238 242 246 248]\n",
      "iteration num : 19\n",
      "train :  [  0   1   2   4   5   6   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  22  24  25  26  27  31  33  34  35  36  37  38  40  41  42  43  44\n",
      "  45  46  48  50  51  52  53  54  55  57  58  59  60  63  65  66  67  69\n",
      "  71  73  74  76  77  79  80  81  82  85  86  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 110 111 112 114\n",
      " 115 117 118 119 120 121 122 123 124 126 127 129 131 132 133 134 136 137\n",
      " 138 139 140 141 143 144 145 146 148 149 150 151 152 154 155 156 157 158\n",
      " 160 161 164 165 166 167 168 169 171 172 173 174 175 176 177 180 182 184\n",
      " 185 186 187 188 189 191 192 194 195 196 197 198 199 201 202 203 204 205\n",
      " 206 207 208 209 210 211 212 213 214 215 216 218 219 220 221 222 223 226\n",
      " 228 229 230 232 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  3   7  21  23  28  29  30  32  39  47  49  56  61  62  64  68  70  72\n",
      "  75  78  83  84  87 109 113 116 125 128 130 135 142 147 153 159 162 163\n",
      " 170 178 179 181 183 190 193 200 217 224 225 227 231 233]\n",
      "[0.7874, 0.8782, 0.9358, 0.7108, 0.6468]\n",
      "mean :  0.7918\n",
      "iteration num : 20\n",
      "train :  [  0   1   2   4   5   6   9  10  11  13  14  16  17  18  21  22  24  25\n",
      "  26  27  28  29  30  31  32  33  34  35  36  37  38  40  43  44  45  46\n",
      "  47  49  50  51  52  53  54  55  57  58  59  60  61  62  64  65  66  67\n",
      "  68  69  70  71  74  77  81  82  83  84  85  86  88  89  90  93  94  95\n",
      "  96  97  98  99 100 101 102 103 104 105 106 108 110 111 112 113 114 115\n",
      " 117 118 119 120 121 122 123 124 126 127 128 129 131 132 134 135 136 137\n",
      " 140 142 145 146 147 149 151 152 153 154 155 156 158 159 161 162 163 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 178 179 180 181 183 184\n",
      " 185 187 188 190 191 192 194 195 196 197 198 199 200 202 204 205 206 207\n",
      " 208 209 211 213 214 215 216 217 218 219 220 221 222 223 224 225 227 228\n",
      " 229 230 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  3   7   8  12  15  19  20  23  39  41  42  48  56  63  72  73  75  76\n",
      "  78  79  80  87  91  92 107 109 116 125 130 133 138 139 141 143 144 148\n",
      " 150 157 160 177 182 186 189 193 201 203 210 212 226 231]\n",
      "iteration num : 21\n",
      "train :  [  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  18  19  20\n",
      "  22  23  25  26  27  28  29  30  34  35  36  37  39  40  41  42  43  46\n",
      "  48  49  50  51  52  53  55  56  57  58  59  60  61  62  63  64  65  66\n",
      "  67  68  69  71  72  73  75  76  78  79  80  81  82  83  85  87  88  89\n",
      "  90  91  92  93  94  95  97  98  99 100 101 102 104 105 107 108 109 110\n",
      " 111 113 114 115 116 117 118 120 121 123 124 125 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 147 148 149 150 151 152 153\n",
      " 154 155 156 157 158 159 160 163 164 166 167 168 169 170 171 172 174 175\n",
      " 176 177 178 179 180 182 183 184 186 188 189 190 191 193 194 195 196 197\n",
      " 198 199 201 202 203 204 205 206 210 212 213 214 215 216 217 218 219 220\n",
      " 221 223 224 226 227 228 229 230 231 232 234 236 237 239 241 243 244 246\n",
      " 247 249] \n",
      "test :  [  4  16  17  21  24  31  32  33  38  44  45  47  54  70  74  77  84  86\n",
      "  96 103 106 112 119 122 126 127 128 146 161 162 165 173 181 185 187 192\n",
      " 200 207 208 209 211 222 225 233 235 238 240 242 245 248]\n",
      "iteration num : 22\n",
      "train :  [  0   1   3   4   5   6   7   8  10  11  12  13  15  16  17  19  20  21\n",
      "  22  23  24  25  27  29  30  31  32  33  35  36  38  39  40  41  42  44\n",
      "  45  46  47  48  49  50  52  54  55  56  60  61  62  63  66  68  70  72\n",
      "  73  74  75  76  77  78  79  80  81  83  84  86  87  88  89  91  92  94\n",
      "  96  97  98 100 101 102 103 105 106 107 108 109 110 111 112 114 115 116\n",
      " 119 120 122 123 125 126 127 128 130 131 132 133 134 135 138 139 140 141\n",
      " 142 143 144 146 147 148 149 150 151 152 153 155 156 157 159 160 161 162\n",
      " 163 164 165 166 167 168 169 171 173 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 192 193 194 195 196 198 200 201 202 203 204 205\n",
      " 206 207 208 209 210 211 212 213 214 215 216 217 218 219 222 224 225 226\n",
      " 227 228 229 230 231 232 233 234 235 236 238 240 241 242 243 244 245 246\n",
      " 248 249] \n",
      "test :  [  2   9  14  18  26  28  34  37  43  51  53  57  58  59  64  65  67  69\n",
      "  71  82  85  90  93  95  99 104 113 117 118 121 124 129 136 137 145 154\n",
      " 158 170 172 174 190 191 197 199 220 221 223 237 239 247]\n",
      "iteration num : 23\n",
      "train :  [  2   3   4   7   8   9  11  12  14  15  16  17  18  19  20  21  22  23\n",
      "  24  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n",
      "  43  44  45  47  48  49  51  53  54  56  57  58  59  61  63  64  65  66\n",
      "  67  69  70  71  72  73  74  75  76  77  78  79  80  82  84  85  86  87\n",
      "  88  89  90  91  92  93  95  96  97  98  99 102 103 104 105 106 107 108\n",
      " 109 110 112 113 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 132 133 134 135 136 137 138 139 141 142 143 144 145 146 147 148 149\n",
      " 150 152 154 157 158 160 161 162 163 165 166 169 170 171 172 173 174 175\n",
      " 176 177 178 179 181 182 183 185 186 187 189 190 191 192 193 196 197 198\n",
      " 199 200 201 203 204 207 208 209 210 211 212 213 214 217 220 221 222 223\n",
      " 225 226 227 228 229 231 232 233 235 237 238 239 240 241 242 243 245 247\n",
      " 248 249] \n",
      "test :  [  0   1   5   6  10  13  25  46  50  52  55  60  62  68  81  83  94 100\n",
      " 101 111 114 115 131 140 151 153 155 156 159 164 167 168 180 184 188 194\n",
      " 195 202 205 206 215 216 218 219 224 230 234 236 244 246]\n",
      "iteration num : 24\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
      "  19  20  21  23  24  25  26  28  31  32  33  34  37  38  39  41  42  43\n",
      "  44  45  46  47  48  50  51  52  53  54  55  56  57  58  59  60  62  63\n",
      "  64  65  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  85  86  87  90  91  92  93  94  95  96  99 100 101 103 104 106\n",
      " 107 109 111 112 113 114 115 116 117 118 119 121 122 124 125 126 127 128\n",
      " 129 130 131 133 136 137 138 139 140 141 143 144 145 146 148 150 151 153\n",
      " 154 155 156 157 158 159 160 161 162 164 165 167 168 170 172 173 174 177\n",
      " 180 181 182 184 185 186 187 188 189 190 191 192 193 194 195 197 199 200\n",
      " 201 202 203 205 206 207 208 209 210 211 212 215 216 218 219 220 221 222\n",
      " 223 224 225 226 230 231 233 234 235 236 237 238 239 240 242 244 245 246\n",
      " 247 248] \n",
      "test :  [ 11  22  27  29  30  35  36  40  49  61  66  88  89  97  98 102 105 108\n",
      " 110 120 123 132 134 135 142 147 149 152 163 166 169 171 175 176 178 179\n",
      " 183 196 198 204 213 214 217 227 228 229 232 241 243 249]\n",
      "[0.6043, 0.878, 0.941, 0.606, 0.6909]\n",
      "mean :  0.7440399999999999\n",
      "iteration num : 25\n",
      "train :  [  0   1   2   3   6   7   8   9  10  11  12  13  14  17  18  20  21  22\n",
      "  24  25  26  27  28  29  30  31  33  34  35  36  37  38  39  41  42  43\n",
      "  44  45  46  47  48  49  50  53  54  55  56  57  58  59  60  63  64  65\n",
      "  66  68  69  71  72  75  77  78  80  81  82  83  84  85  86  87  88  90\n",
      "  91  92  93  94  95  96  97  98 101 102 103 104 105 106 107 109 110 113\n",
      " 114 115 117 118 119 120 121 122 124 125 126 127 128 129 130 131 132 134\n",
      " 135 137 138 139 141 142 143 144 145 146 148 149 150 151 152 153 154 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173\n",
      " 174 175 178 179 180 182 183 186 187 188 189 192 193 194 195 197 198 199\n",
      " 200 202 204 205 206 208 209 210 211 212 213 214 216 217 218 219 220 222\n",
      " 225 226 227 228 230 231 232 233 234 236 237 238 240 241 242 243 244 245\n",
      " 246 248] \n",
      "test :  [  4   5  15  16  19  23  32  40  51  52  61  62  67  70  73  74  76  79\n",
      "  89  99 100 108 111 112 116 123 133 136 140 147 176 177 181 184 185 190\n",
      " 191 196 201 203 207 215 221 223 224 229 235 239 247 249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 26\n",
      "train :  [  0   3   4   5   6   7  10  11  12  13  14  15  16  18  19  21  22  23\n",
      "  24  25  26  28  29  30  31  32  33  34  35  36  39  40  41  42  44  46\n",
      "  48  49  50  51  52  53  54  56  59  61  62  63  65  66  67  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  93  94  95  96  97  98  99 100 101 102 104 105 108 110 111 112\n",
      " 113 114 115 116 119 121 123 124 125 126 127 128 130 131 132 133 134 135\n",
      " 136 139 140 141 145 146 147 148 149 150 152 154 155 156 157 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 176 177 178 180 181 183\n",
      " 184 185 186 187 189 190 191 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 207 208 209 210 211 212 213 214 215 216 217 218 219 221 222 223\n",
      " 224 225 226 227 228 229 231 232 233 235 236 237 238 239 240 244 245 246\n",
      " 247 249] \n",
      "test :  [  1   2   8   9  17  20  27  37  38  43  45  47  55  57  58  60  64  68\n",
      "  92 103 106 107 109 117 118 120 122 129 137 138 142 143 144 151 153 158\n",
      " 174 175 179 182 188 192 206 220 230 234 241 242 243 248]\n",
      "iteration num : 27\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  11  13  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  28  29  30  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  45  46  47  48  49  51  52  54  55  57  58  59  60  61\n",
      "  62  64  65  66  67  68  70  71  72  73  74  75  76  78  79  81  83  84\n",
      "  85  86  87  88  89  90  92  96  98  99 100 103 106 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 120 121 122 123 124 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 142 143 144 145 146 147 151 152 153\n",
      " 154 155 156 157 158 159 161 162 163 164 165 166 167 168 172 174 175 176\n",
      " 177 178 179 181 182 184 185 186 188 189 190 191 192 193 194 196 198 201\n",
      " 202 203 204 205 206 207 208 209 210 214 215 216 217 219 220 221 222 223\n",
      " 224 226 229 230 232 233 234 235 236 237 238 239 241 242 243 244 245 247\n",
      " 248 249] \n",
      "test :  [ 12  14  24  31  44  50  53  56  63  69  77  80  82  91  93  94  95  97\n",
      " 101 102 104 105 119 125 141 148 149 150 160 169 170 171 173 180 183 187\n",
      " 195 197 199 200 211 212 213 218 225 227 228 231 240 246]\n",
      "iteration num : 28\n",
      "train :  [  0   1   2   4   5   6   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  22  23  24  26  27  29  30  31  32  34  35  37  38  40  41  42  43  44\n",
      "  45  47  48  49  50  51  52  53  54  55  56  57  58  60  61  62  63  64\n",
      "  67  68  69  70  71  72  73  74  75  76  77  78  79  80  82  83  87  89\n",
      "  91  92  93  94  95  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 115 116 117 118 119 120 121 122 123 124 125 129 130 131\n",
      " 133 134 136 137 138 140 141 142 143 144 147 148 149 150 151 153 157 158\n",
      " 160 161 163 164 167 168 169 170 171 173 174 175 176 177 179 180 181 182\n",
      " 183 184 185 186 187 188 190 191 192 195 196 197 198 199 200 201 203 204\n",
      " 206 207 208 209 211 212 213 215 216 217 218 219 220 221 222 223 224 225\n",
      " 227 228 229 230 231 233 234 235 236 237 238 239 240 241 242 243 246 247\n",
      " 248 249] \n",
      "test :  [  3   7  11  21  25  28  33  36  39  46  59  65  66  81  84  85  86  88\n",
      "  90  96 114 126 127 128 132 135 139 145 146 152 154 155 156 159 162 165\n",
      " 166 172 178 189 193 194 202 205 210 214 226 232 244 245]\n",
      "iteration num : 29\n",
      "train :  [  1   2   3   4   5   7   8   9  11  12  14  15  16  17  19  20  21  23\n",
      "  24  25  27  28  31  32  33  36  37  38  39  40  43  44  45  46  47  50\n",
      "  51  52  53  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  73  74  76  77  79  80  81  82  84  85  86  88  89  90  91  92  93\n",
      "  94  95  96  97  99 100 101 102 103 104 105 106 107 108 109 111 112 114\n",
      " 116 117 118 119 120 122 123 125 126 127 128 129 132 133 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 158 159 160 162 165 166 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 187 188 189 190 191 192 193 194 195 196 197 199 200\n",
      " 201 202 203 205 206 207 210 211 212 213 214 215 218 220 221 223 224 225\n",
      " 226 227 228 229 230 231 232 234 235 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  0   6  10  13  18  22  26  29  30  34  35  41  42  48  49  54  71  72\n",
      "  75  78  83  87  98 110 113 115 121 124 130 131 134 157 161 163 164 167\n",
      " 168 186 198 204 208 209 216 217 219 222 233 236 237 238]\n",
      "[0.8715, 0.8294, 0.7587, 0.6819, 0.6072]\n",
      "mean :  0.7497399999999999\n",
      "iteration num : 30\n",
      "train :  [  0   1   3   4   5   6   7   8   9  10  11  14  15  16  17  18  20  22\n",
      "  23  24  26  27  29  30  31  32  33  34  35  36  37  39  40  41  43  44\n",
      "  45  46  47  48  50  51  52  54  55  56  58  59  60  62  63  64  66  67\n",
      "  69  71  72  74  75  78  79  82  83  85  86  87  88  89  90  91  92  93\n",
      "  94  96  97  98  99 100 101 104 105 107 108 109 110 111 112 113 114 118\n",
      " 120 121 122 123 125 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 143 144 145 146 147 148 149 150 151 152 153 155 156 157 158 159 160\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 184 185 186 187 188 189 190 191 193 197 198 199 201 202 203\n",
      " 204 205 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 224\n",
      " 225 226 227 228 230 232 233 235 236 237 238 239 240 241 243 244 245 246\n",
      " 247 248] \n",
      "test :  [  2  12  13  19  21  25  28  38  42  49  53  57  61  65  68  70  73  76\n",
      "  77  80  81  84  95 102 103 106 115 116 117 119 124 126 141 142 154 161\n",
      " 183 192 194 195 196 200 206 222 223 229 231 234 242 249]\n",
      "iteration num : 31\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
      "  19  20  21  23  24  25  26  28  29  32  33  35  36  38  39  42  43  44\n",
      "  45  49  50  51  52  53  54  55  56  57  58  59  60  61  62  65  66  67\n",
      "  68  69  70  71  72  73  75  76  77  79  80  81  82  83  84  86  87  88\n",
      "  89  92  93  94  95  97  98 100 101 102 103 104 105 106 109 110 112 113\n",
      " 114 115 116 117 118 119 121 122 123 124 125 126 127 128 130 131 132 133\n",
      " 135 136 137 138 139 140 141 142 143 144 146 147 148 151 152 153 154 155\n",
      " 156 157 158 160 161 162 163 164 166 167 170 171 172 173 174 175 176 177\n",
      " 178 179 181 182 183 184 188 189 190 191 192 193 194 195 196 198 200 201\n",
      " 202 203 205 206 210 211 212 213 214 215 217 218 219 220 221 222 223 224\n",
      " 225 227 228 229 231 232 234 235 236 237 238 239 240 241 242 244 246 247\n",
      " 248 249] \n",
      "test :  [ 11  22  27  30  31  34  37  40  41  46  47  48  63  64  74  78  85  90\n",
      "  91  96  99 107 108 111 120 129 134 145 149 150 159 165 168 169 180 185\n",
      " 186 187 197 199 204 207 208 209 216 226 230 233 243 245]\n",
      "iteration num : 32\n",
      "train :  [  0   1   2   4   5   6   7  10  11  12  13  14  17  19  20  21  22  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  37  38  40  41  42  43  44\n",
      "  46  47  48  49  50  52  53  54  55  57  58  60  61  63  64  65  66  67\n",
      "  68  70  71  72  73  74  76  77  78  79  80  81  82  84  85  87  90  91\n",
      "  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108 111 112 114\n",
      " 115 116 117 119 120 121 122 123 124 125 126 127 129 130 131 132 133 134\n",
      " 135 136 139 140 141 142 143 144 145 146 147 148 149 150 151 153 154 155\n",
      " 156 158 159 160 161 162 164 165 167 168 169 170 171 172 173 174 175 176\n",
      " 177 178 180 181 183 184 185 186 187 188 190 192 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206 207 208 209 210 211 213 215 216 217 222 223\n",
      " 224 225 226 227 228 229 230 231 233 234 235 240 241 242 243 244 245 247\n",
      " 248 249] \n",
      "test :  [  3   8   9  15  16  18  23  36  39  45  51  56  59  62  69  75  83  86\n",
      "  88  89  92 104 109 110 113 118 128 137 138 152 157 163 166 179 182 189\n",
      " 191 193 212 214 218 219 220 221 232 236 237 238 239 246]\n",
      "iteration num : 33\n",
      "train :  [  1   2   3   5   6   8   9  10  11  12  13  15  16  17  18  19  21  22\n",
      "  23  25  27  28  29  30  31  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  53  55  56  57  59  61  62  63  64  65  67\n",
      "  68  69  70  71  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  95  96  98  99 101 102 103 104 105 106 107\n",
      " 108 109 110 111 113 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 131 132 134 135 137 138 141 142 143 145 148 149 150 151 152 153\n",
      " 154 157 158 159 161 163 164 165 166 168 169 172 174 175 177 178 179 180\n",
      " 182 183 184 185 186 187 188 189 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 206 207 208 209 211 212 214 215 216 217 218 219 220 221\n",
      " 222 223 226 227 229 230 231 232 233 234 236 237 238 239 242 243 244 245\n",
      " 246 249] \n",
      "test :  [  0   4   7  14  20  24  26  32  33  52  54  58  60  66  72  94  97 100\n",
      " 112 114 130 133 136 139 140 144 146 147 155 156 160 162 167 170 171 173\n",
      " 176 181 190 205 210 213 224 225 228 235 240 241 247 248]\n",
      "iteration num : 34\n",
      "train :  [  0   2   3   4   7   8   9  11  12  13  14  15  16  18  19  20  21  22\n",
      "  23  24  25  26  27  28  30  31  32  33  34  36  37  38  39  40  41  42\n",
      "  45  46  47  48  49  51  52  53  54  56  57  58  59  60  61  62  63  64\n",
      "  65  66  68  69  70  72  73  74  75  76  77  78  80  81  83  84  85  86\n",
      "  88  89  90  91  92  94  95  96  97  99 100 102 103 104 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 124 126 128 129 130 133 134\n",
      " 136 137 138 139 140 141 142 144 145 146 147 149 150 152 154 155 156 157\n",
      " 159 160 161 162 163 165 166 167 168 169 170 171 173 176 179 180 181 182\n",
      " 183 185 186 187 189 190 191 192 193 194 195 196 197 199 200 204 205 206\n",
      " 207 208 209 210 212 213 214 216 218 219 220 221 222 223 224 225 226 228\n",
      " 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 245 246 247\n",
      " 248 249] \n",
      "test :  [  1   5   6  10  17  29  35  43  44  50  55  67  71  79  82  87  93  98\n",
      " 101 105 121 122 123 125 127 131 132 135 143 148 151 153 158 164 172 174\n",
      " 175 177 178 184 188 198 201 202 203 211 215 217 227 244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8044, 0.703, 0.7914, 0.894, 0.6507]\n",
      "mean :  0.7687\n",
      "iteration num : 35\n",
      "train :  [  0   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  25  26  27  29  30  31  32  33  34  36  38  39  40  41\n",
      "  42  44  45  46  47  48  49  52  53  55  56  57  58  60  61  62  63  64\n",
      "  65  66  68  69  70  71  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  89  90  91  92  93  94  96  97  99 100 103 104 106 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130\n",
      " 131 132 134 135 137 138 139 140 141 143 144 145 148 149 152 154 155 156\n",
      " 157 160 161 163 164 165 167 168 170 171 172 174 176 178 179 181 182 183\n",
      " 184 185 186 187 188 189 191 192 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206 207 208 209 211 212 213 214 215 216 217 218 220 222 224 225\n",
      " 226 227 228 229 230 231 232 233 234 237 239 240 241 242 243 244 245 247\n",
      " 248 249] \n",
      "test :  [  1   2  24  28  35  37  43  50  51  54  59  67  72  73  74  88  95  98\n",
      " 101 102 105 107 122 133 136 142 146 147 150 151 153 158 159 162 166 169\n",
      " 173 175 177 180 190 193 210 219 221 223 235 236 238 246]\n",
      "iteration num : 36\n",
      "train :  [  0   1   2   4   5   6   7   8   9  11  12  13  14  16  17  18  19  20\n",
      "  21  23  24  26  27  28  29  31  33  34  35  37  39  40  41  42  43  45\n",
      "  46  47  49  50  51  53  54  55  56  59  60  61  62  63  64  65  66  67\n",
      "  68  69  70  71  72  73  74  75  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  91  92  93  95  96  98  99 100 101 102 103 104 105 106 107\n",
      " 108 110 111 112 113 114 115 117 119 120 122 123 124 125 126 127 128 129\n",
      " 130 132 133 135 136 138 141 142 144 146 147 148 149 150 151 152 153 154\n",
      " 155 157 158 159 160 161 162 164 166 167 168 169 171 172 173 174 175 177\n",
      " 178 180 181 182 183 184 187 188 189 190 191 192 193 194 196 198 199 200\n",
      " 201 202 203 204 205 206 207 208 209 210 211 212 214 215 216 217 218 219\n",
      " 220 221 223 224 225 227 228 229 230 234 235 236 238 239 240 241 242 244\n",
      " 246 248] \n",
      "test :  [  3  10  15  22  25  30  32  36  38  44  48  52  57  58  76  90  94  97\n",
      " 109 116 118 121 131 134 137 139 140 143 145 156 163 165 170 176 179 185\n",
      " 186 195 197 213 222 226 231 232 233 237 243 245 247 249]\n",
      "iteration num : 37\n",
      "train :  [  1   2   3   5   6   7   8   9  10  12  14  15  17  18  19  20  22  23\n",
      "  24  25  26  27  28  29  30  31  32  35  36  37  38  39  40  42  43  44\n",
      "  45  46  47  48  49  50  51  52  54  55  56  57  58  59  60  61  62  63\n",
      "  64  66  67  68  70  71  72  73  74  75  76  78  81  82  83  84  86  87\n",
      "  88  89  90  91  93  94  95  97  98  99 100 101 102 104 105 107 108 109\n",
      " 112 114 115 116 117 118 120 121 122 124 125 126 128 130 131 133 134 135\n",
      " 136 137 139 140 142 143 145 146 147 148 150 151 152 153 154 155 156 157\n",
      " 158 159 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176\n",
      " 177 179 180 182 185 186 187 189 190 192 193 194 195 196 197 198 199 200\n",
      " 202 203 204 205 208 210 211 213 217 219 220 221 222 223 225 226 227 229\n",
      " 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  0   4  11  13  16  21  33  34  41  53  65  69  77  79  80  85  92  96\n",
      " 103 106 110 111 113 119 123 127 129 132 138 141 144 149 160 178 181 183\n",
      " 184 188 191 201 206 207 209 212 214 215 216 218 224 228]\n",
      "iteration num : 38\n",
      "train :  [  0   1   2   3   4  10  11  13  15  16  17  18  21  22  23  24  25  28\n",
      "  29  30  32  33  34  35  36  37  38  39  40  41  42  43  44  48  50  51\n",
      "  52  53  54  55  57  58  59  60  65  67  68  69  70  71  72  73  74  76\n",
      "  77  79  80  81  82  85  86  88  90  92  94  95  96  97  98 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 116 118 119 120 121 122\n",
      " 123 125 126 127 129 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 165 166 167 168 169 170 173 175 176 177 178 179 180 181 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 197 198 201 202 204 205 206\n",
      " 207 208 209 210 212 213 214 215 216 217 218 219 221 222 223 224 225 226\n",
      " 227 228 231 232 233 234 235 236 237 238 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  5   6   7   8   9  12  14  19  20  26  27  31  45  46  47  49  56  61\n",
      "  62  63  64  66  75  78  83  84  87  89  91  93  99 115 117 124 128 130\n",
      " 164 171 172 174 182 196 199 200 203 211 220 229 230 239]\n",
      "iteration num : 39\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  19\n",
      "  20  21  22  24  25  26  27  28  30  31  32  33  34  35  36  37  38  41\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  56  57  58  59  61  62\n",
      "  63  64  65  66  67  69  72  73  74  75  76  77  78  79  80  83  84  85\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 101 102 103 105 106\n",
      " 107 109 110 111 113 115 116 117 118 119 121 122 123 124 127 128 129 130\n",
      " 131 132 133 134 136 137 138 139 140 141 142 143 144 145 146 147 149 150\n",
      " 151 153 156 158 159 160 162 163 164 165 166 169 170 171 172 173 174 175\n",
      " 176 177 178 179 180 181 182 183 184 185 186 188 190 191 193 195 196 197\n",
      " 199 200 201 203 206 207 209 210 211 212 213 214 215 216 218 219 220 221\n",
      " 222 223 224 226 228 229 230 231 232 233 235 236 237 238 239 243 245 246\n",
      " 247 249] \n",
      "test :  [ 17  18  23  29  39  40  42  55  60  68  70  71  81  82  86 100 104 108\n",
      " 112 114 120 125 126 135 148 152 154 155 157 161 167 168 187 189 192 194\n",
      " 198 202 204 205 208 217 225 227 234 240 241 242 244 248]\n",
      "[0.9186, 0.6524, 0.6801, 0.749, 0.9041]\n",
      "mean :  0.7808400000000001\n",
      "iteration num : 40\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  13  16  18  19  20  21  22\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42\n",
      "  43  44  45  46  47  48  49  50  51  53  54  55  56  57  58  59  60  61\n",
      "  62  63  64  65  66  67  69  70  71  72  73  74  75  76  77  78  79  81\n",
      "  82  83  84  86  87  88  89  90  92  95 100 102 104 105 106 108 109 110\n",
      " 111 112 113 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 131 132 133 134 135 137 139 142 143 144 145 146 148 149 150 151 152 153\n",
      " 154 155 157 158 159 160 162 163 165 166 168 172 173 174 175 176 177 178\n",
      " 179 180 181 182 184 185 186 187 189 190 191 192 194 195 196 197 198 199\n",
      " 200 201 202 204 205 206 209 212 214 215 216 217 218 219 221 222 223 224\n",
      " 225 226 227 228 230 231 232 233 235 236 237 238 239 240 241 242 243 244\n",
      " 245 249] \n",
      "test :  [ 11  12  14  15  17  23  41  52  68  80  85  91  93  94  96  97  98  99\n",
      " 101 103 107 114 130 136 138 140 141 147 156 161 164 167 169 170 171 183\n",
      " 188 193 203 207 208 210 211 213 220 229 234 246 247 248]\n",
      "iteration num : 41\n",
      "train :  [  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  20\n",
      "  23  24  26  28  32  33  34  36  37  38  39  40  41  42  43  44  45  46\n",
      "  47  48  51  52  54  55  56  57  58  59  60  62  63  64  66  67  68  69\n",
      "  70  71  72  74  75  76  77  78  80  81  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 103 105 106 107 109 110 111\n",
      " 112 113 114 115 116 117 118 119 121 122 123 124 125 126 129 130 131 132\n",
      " 133 134 136 137 138 139 140 141 143 144 145 147 151 153 155 156 157 158\n",
      " 159 160 161 163 164 165 167 169 170 171 173 174 176 177 178 179 180 181\n",
      " 183 184 185 186 187 188 191 192 193 195 196 198 199 200 201 203 204 205\n",
      " 207 208 209 210 211 212 213 215 216 217 218 219 220 221 222 223 224 226\n",
      " 228 229 230 231 232 233 234 235 236 237 239 240 241 242 243 244 245 246\n",
      " 247 248] \n",
      "test :  [  2  16  19  21  22  25  27  29  30  31  35  49  50  53  61  65  73  79\n",
      "  82 102 104 108 120 127 128 135 142 146 148 149 150 152 154 162 166 168\n",
      " 172 175 182 189 190 194 197 202 206 214 225 227 238 249]\n",
      "iteration num : 42\n",
      "train :  [  1   2   3   4   6   7   9  11  12  13  14  15  16  17  19  21  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  38  40  41  43  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  60  61  62  63  65\n",
      "  66  68  69  70  71  73  74  75  76  79  80  81  82  84  85  86  88  89\n",
      "  91  92  93  94  95  96  97  98  99 101 102 103 104 107 108 111 112 113\n",
      " 114 116 117 119 120 121 122 123 124 125 126 127 128 129 130 132 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 152 154 155\n",
      " 156 157 158 159 160 161 162 163 164 166 167 168 169 170 171 172 173 175\n",
      " 176 181 182 183 185 186 187 188 189 190 191 192 193 194 196 197 198 199\n",
      " 201 202 203 206 207 208 209 210 211 212 213 214 215 216 219 220 221 222\n",
      " 223 225 227 229 232 233 234 235 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  0   5   8  10  18  20  37  39  42  44  59  64  67  72  77  78  83  87\n",
      "  90 100 105 106 109 110 115 118 131 133 151 153 165 174 177 178 179 180\n",
      " 184 195 200 204 205 217 218 224 226 228 230 231 236 237]\n",
      "iteration num : 43\n",
      "train :  [  0   2   3   5   6   8  10  11  12  13  14  15  16  17  18  19  20  21\n",
      "  22  23  24  25  27  29  30  31  35  37  39  41  42  43  44  45  46  47\n",
      "  48  49  50  52  53  54  57  59  61  63  64  65  67  68  70  72  73  76\n",
      "  77  78  79  80  82  83  84  85  86  87  89  90  91  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 113 114 115 116 117\n",
      " 118 119 120 123 125 126 127 128 129 130 131 132 133 135 136 137 138 139\n",
      " 140 141 142 143 144 146 147 148 149 150 151 152 153 154 155 156 158 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 188 189 190 191 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 205 206 207 208 209 210 211 213 214 216 217 218 219 220\n",
      " 222 223 224 225 226 227 228 229 230 231 234 235 236 237 238 241 246 247\n",
      " 248 249] \n",
      "test :  [  1   4   7   9  26  28  32  33  34  36  38  40  51  55  56  58  60  62\n",
      "  66  69  71  74  75  81  88  92 111 112 121 122 124 134 145 157 159 160\n",
      " 173 187 192 212 215 221 232 233 239 240 242 243 244 245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration num : 44\n",
      "train :  [  0   1   2   4   5   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  44  49  50  51  52  53  55  56  58  59  60  61  62  64  65\n",
      "  66  67  68  69  71  72  73  74  75  77  78  79  80  81  82  83  85  87\n",
      "  88  90  91  92  93  94  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 114 115 118 120 121 122 124 127 128 130 131 133 134\n",
      " 135 136 138 140 141 142 145 146 147 148 149 150 151 152 153 154 156 157\n",
      " 159 160 161 162 164 165 166 167 168 169 170 171 172 173 174 175 177 178\n",
      " 179 180 182 183 184 187 188 189 190 192 193 194 195 197 200 202 203 204\n",
      " 205 206 207 208 210 211 212 213 214 215 217 218 220 221 224 225 226 227\n",
      " 228 229 230 231 232 233 234 236 237 238 239 240 242 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [  3   6  13  24  43  45  46  47  48  54  57  63  70  76  84  86  89  95\n",
      " 113 116 117 119 123 125 126 129 132 137 139 143 144 155 158 163 176 181\n",
      " 185 186 191 196 198 199 201 209 216 219 222 223 235 241]\n",
      "[0.8103, 0.5774, 0.6313, 0.9505, 0.7854]\n",
      "mean :  0.75098\n",
      "iteration num : 45\n",
      "train :  [  1   2   3   4   5   6   7   9  10  11  12  13  14  15  16  17  19  20\n",
      "  21  23  25  27  29  32  33  34  35  37  40  41  42  43  44  45  46  47\n",
      "  49  50  51  52  53  54  55  56  59  60  61  62  63  64  65  66  68  69\n",
      "  71  72  73  74  75  76  77  78  79  80  82  83  84  85  86  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 113 114 115 116 117 118 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 140 142 143 145 146 147 148 149\n",
      " 151 153 154 156 157 158 159 160 161 162 163 166 167 170 171 172 175 176\n",
      " 177 178 179 180 181 182 183 185 186 188 189 192 193 194 195 196 198 199\n",
      " 200 202 203 204 205 206 207 208 209 210 211 212 213 215 216 219 220 222\n",
      " 223 225 226 229 230 232 233 235 236 237 238 239 240 242 243 244 245 246\n",
      " 247 249] \n",
      "test :  [  0   8  18  22  24  26  28  30  31  36  38  39  48  57  58  67  70  81\n",
      "  87 111 112 119 141 144 150 152 155 164 165 168 169 173 174 184 187 190\n",
      " 191 197 201 214 217 218 221 224 227 228 231 234 241 248]\n",
      "iteration num : 46\n",
      "train :  [  0   1   5   6   7   8   9  10  12  13  16  17  18  19  20  22  23  24\n",
      "  25  26  27  28  30  31  32  33  34  35  36  37  38  39  40  41  42  43\n",
      "  44  45  46  48  49  50  51  52  53  55  56  57  58  59  60  62  63  65\n",
      "  67  68  70  72  73  75  76  77  79  80  81  82  84  86  87  88  90  91\n",
      "  92  94  95  96  97  98 101 102 105 106 108 110 111 112 113 114 115 117\n",
      " 118 119 120 121 122 123 124 126 127 129 130 131 132 133 134 136 137 138\n",
      " 139 140 141 142 143 144 148 149 150 151 152 153 155 157 159 160 161 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 183\n",
      " 184 185 186 187 188 189 190 191 192 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206 207 209 211 212 213 214 215 216 217 218 219 220 221 223\n",
      " 224 225 227 228 229 231 232 233 234 235 236 238 240 241 242 245 246 247\n",
      " 248 249] \n",
      "test :  [  2   3   4  11  14  15  21  29  47  54  61  64  66  69  71  74  78  83\n",
      "  85  89  93  99 100 103 104 107 109 116 125 128 135 145 146 147 154 156\n",
      " 158 162 163 182 193 208 210 222 226 230 237 239 243 244]\n",
      "iteration num : 47\n",
      "train :  [  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
      "  20  21  22  24  25  26  27  28  29  30  31  32  33  35  36  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  53  54  56  57  58  60  61\n",
      "  62  63  64  65  66  67  68  69  70  71  74  75  77  78  79  80  81  83\n",
      "  84  85  86  87  88  89  90  92  93  94  97  99 100 101 103 104 105 106\n",
      " 107 109 110 111 112 114 115 116 118 119 121 122 125 126 128 129 130 131\n",
      " 132 134 135 137 141 142 143 144 145 146 147 149 150 151 152 153 154 155\n",
      " 156 157 158 160 161 162 163 164 165 166 168 169 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 189 190 191 193 194 195 197 198 199\n",
      " 200 201 202 204 206 207 208 210 211 212 214 217 218 219 221 222 224 225\n",
      " 226 227 228 229 230 231 232 234 236 237 238 239 241 243 244 245 246 247\n",
      " 248 249] \n",
      "test :  [ 12  19  23  34  37  52  55  59  72  73  76  82  91  95  96  98 102 108\n",
      " 113 117 120 123 124 127 133 136 138 139 140 148 159 167 170 171 172 188\n",
      " 192 196 203 205 209 213 215 216 220 223 233 235 240 242]\n",
      "iteration num : 48\n",
      "train :  [  0   2   3   4   7   8   9  10  11  12  14  15  18  19  21  22  23  24\n",
      "  25  26  27  28  29  30  31  33  34  35  36  37  38  39  40  42  45  46\n",
      "  47  48  50  52  53  54  55  57  58  59  60  61  62  63  64  66  67  69\n",
      "  70  71  72  73  74  76  78  79  81  82  83  85  86  87  89  91  93  95\n",
      "  96  97  98  99 100 101 102 103 104 106 107 108 109 111 112 113 116 117\n",
      " 119 120 121 122 123 124 125 126 127 128 130 133 134 135 136 137 138 139\n",
      " 140 141 143 144 145 146 147 148 150 152 154 155 156 157 158 159 160 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 179 180 181 182\n",
      " 184 187 188 189 190 191 192 193 195 196 197 198 199 200 201 202 203 205\n",
      " 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 226\n",
      " 227 228 229 230 231 232 233 234 235 237 238 239 240 241 242 243 244 245\n",
      " 247 248] \n",
      "test :  [  1   5   6  13  16  17  20  32  41  43  44  49  51  56  65  68  75  77\n",
      "  80  84  88  90  92  94 105 110 114 115 118 129 131 132 142 149 151 153\n",
      " 161 177 178 183 185 186 194 204 206 207 225 236 246 249]\n",
      "iteration num : 49\n",
      "train :  [  0   1   2   3   4   5   6   8  11  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  26  28  29  30  31  32  34  36  37  38  39  41  43  44\n",
      "  47  48  49  51  52  54  55  56  57  58  59  61  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  80  81  82  83  84  85  87  88  89\n",
      "  90  91  92  93  94  95  96  98  99 100 102 103 104 105 107 108 109 110\n",
      " 111 112 113 114 115 116 117 118 119 120 123 124 125 127 128 129 131 132\n",
      " 133 135 136 138 139 140 141 142 144 145 146 147 148 149 150 151 152 153\n",
      " 154 155 156 158 159 161 162 163 164 165 167 168 169 170 171 172 173 174\n",
      " 177 178 182 183 184 185 186 187 188 190 191 192 193 194 196 197 201 203\n",
      " 204 205 206 207 208 209 210 213 214 215 216 217 218 220 221 222 223 224\n",
      " 225 226 227 228 230 231 233 234 235 236 237 239 240 241 242 243 244 246\n",
      " 248 249] \n",
      "test :  [  7   9  10  25  27  33  35  40  42  45  46  50  53  60  62  63  79  86\n",
      "  97 101 106 121 122 126 130 134 137 143 157 160 166 175 176 179 180 181\n",
      " 189 195 198 199 200 202 211 212 219 229 232 238 245 247]\n",
      "[0.7409, 0.7103, 0.9162, 0.6307, 0.7854]\n",
      "mean :  0.7567\n",
      "total fold mean :  0.7626\n",
      "total cv mean :  0.7626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fold setting\n",
    "kf = RepeatedKFold(n_splits = 5,n_repeats=10)\n",
    "kf.get_n_splits(x_train)\n",
    "#kf\n",
    "#>>> KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "#for numbering k folds\n",
    "i=0\n",
    "cv_rmse = []\n",
    "cv_rmse_mean = []\n",
    "tmp = []\n",
    "\n",
    "#DataFrame generate\n",
    "y_pic_pred_result = pd.DataFrame()\n",
    "y_pic_pred_result['idx'] = pd.Series([i for i in range(len(y))])\n",
    "\n",
    "\n",
    "#model generate\n",
    "neigh = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "\n",
    "#cross-val training\n",
    "for train_idx, test_idx in kf.split(x_train):\n",
    "    print(\"iteration num : {}\".format(i))\n",
    "    print(\"train : \", train_idx, \"\\ntest : \", test_idx)\n",
    "    x_cv_train , x_cv_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "    y_cv_train , y_cv_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    \n",
    "    neigh.fit(x_cv_train,y_cv_train)\n",
    "    \n",
    "    y_cv_testidx = test_idx\n",
    "    y_cv_pred = neigh.predict(x_cv_test)\n",
    "    cv_rmse.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    cv_rmse_mean.append(round(np.sqrt(mean_squared_error(y_cv_test,y_cv_pred)),4))\n",
    "    \n",
    "    y_pic_pred_result['y_cv_testidx_{}'.format(i)] = pd.Series()\n",
    "    y_pic_pred_result['y_cv_pred_{}'.format(i)] = pd.Series()\n",
    "    \n",
    "    for j in range(len(y_cv_testidx)):\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_testidx_{}'.format(i)] = y_cv_testidx[j]\n",
    "        y_pic_pred_result.loc[y_cv_testidx[j],'y_cv_pred_{}'.format(i)] = y_cv_pred[j]\n",
    "        \n",
    "    \n",
    "    \n",
    "    #y_pic_pred_result['y_cv_testidx_{}'.format(i)] = pd.Series(y_cv_testidx)\n",
    "    #y_pic_pred_result['y_cv_pred_{}'.format(i)] = pd.Series(y_cv_pred)\n",
    "    i += 1 \n",
    "    \n",
    "    if i % 5 == 0 : \n",
    "        tmp.append(np.mean(cv_rmse_mean))\n",
    "        print(cv_rmse_mean) # per fold rmse value in one cv \n",
    "        print(\"mean : \",np.mean(cv_rmse_mean)) # RMSE mean value per iteration of cv  \n",
    "        cv_rmse_mean.clear()\n",
    "        \n",
    "\n",
    "print(\"total fold mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total cv mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "\n",
    "#model retrain with all train data  \n",
    "neigh.fit(x_train,y_train) # > model train\n",
    "y_pic_test_pred = neigh.predict(x_test) # > model predidction\n",
    "\n",
    "# \n",
    "y_pic_test_pred_df = pd.DataFrame(columns=['y_pic_test_idx','y_pic_test_pred'])\n",
    "for j in range(len(x_test_idx)):\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_idx'] = x_test_idx[j]\n",
    "        y_pic_test_pred_df.loc[x_test_idx[j],'y_pic_test_pred'] = y_pic_test_pred[j]\n",
    "#y_pic_test_pred_df = pd.DataFrame(y_pic_test_pred,columns=['y_pic_test_pred'])\n",
    "y_pic_pred_result = pd.concat([y_pic_pred_result, y_pic_test_pred_df], axis=1, ignore_index=False)\n",
    "\n",
    "#save csv \n",
    "y_pic_pred_result.to_csv(result_wdir+'5-alpha-reductase_dltnan_y_pic_pred_result.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fold rmse mean :  0.7626\n",
      "total cv rmse mean :  0.7626\n",
      "each cv rmse average : \n",
      "[0.75148, 0.7835799999999999, 0.74776, 0.7918, 0.7440399999999999, 0.7497399999999999, 0.7687, 0.7808400000000001, 0.75098, 0.7567] \n",
      "variance of rmse of every folds : 0.0121 \n",
      "train data size : 250 (0.9%)\n",
      " test data size : 28 (0.1%)\n"
     ]
    }
   ],
   "source": [
    "#RESULT\n",
    "print(\"total fold rmse mean : \", round(np.mean(cv_rmse),4)) # mean of 50 cv rmse (1회 iter돌 때의 모든 rmse의 평균 (50회의 평균)) \n",
    "print(\"total cv rmse mean : \",round(np.mean(tmp),4)) # mean of cv's mean of 1 iter (각 cv rmse 평균의 평균) # we need var of this value \n",
    "print(\"each cv rmse average : \\n{} \\nvariance of rmse of every folds : {} \".format(tmp,round(np.var(cv_rmse),4)))\n",
    "print(\"train data size : {} ({}%)\\n\".format(len(x_train),round((len(x_train)/len(x)),2)), \"test data size : {} ({}%)\".format(len(x_test),round((len(x_test)/len(x)),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get inverse pic , predicted Standard Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pic = y_pic_pred_result['y_pic_test_pred']\n",
    "y_compare = np.power(10, (9-y_pic))\n",
    "print(y[250:], y_compare[:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get mse and rmse of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.58 | RMSE : 0.76 \n"
     ]
    }
   ],
   "source": [
    "MSE_v0_3 = mean_squared_error(y_test,y_pic_test_pred)\n",
    "MSE_v0_3\n",
    "RMSE_v0_3 = np.sqrt(MSE_v0_3)\n",
    "RMSE_v0_3\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} \".format(MSE_v0_3,RMSE_v0_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 1 _spliting data for train as 0.9 and test as 0.1 / get rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "neigh.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_pred_test = pd.DataFrame(neigh.predict(x_test),columns=['neigh_pred_test'])\n",
    "neigh_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 - 1) RMSE with data splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(y_test,neigh_pred_test)\n",
    "MSE\n",
    "RMSE = np.sqrt(MSE)\n",
    "RMSE\n",
    "log_RMSE = np.log(RMSE)\n",
    "log_RMSE\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} | log RMSE : {:.2f}\".format(MSE, RMSE, log_RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 - 2) RMSE with cv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "cv=5\n",
    "neg_mse_cv = cross_val_score(neigh,\n",
    "                            x,\n",
    "                            y,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=cv)\n",
    "mse_cv_ = (-1)*neg_mse_cv\n",
    "rmse_cv_ = np.sqrt(mse_cv_)\n",
    "log_rmse_cv_ = np.log(rmse_cv_)\n",
    "\n",
    "log_rmse_cv_mean = np.sum(log_rmse_cv_)/cv\n",
    "log_rmse_cv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  #1 - demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 94\n",
    "test_x = []\n",
    "test_x = x.loc[num][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target value\n",
    "# >>> y.loc[num]\n",
    "# predict value \n",
    "# >>> neigh.predict([test_x])\n",
    "print('target value : {}\\npredict value : {}'.format(y.loc[num],neigh.predict([test_x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 2 _using log scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_log = []\n",
    "for i in range(len(y)):\n",
    "    y_log.append(np.log(y.loc[i]))\n",
    "    \n",
    "y_log_df = pd.DataFrame(y_log,columns=['stdval_log'])\n",
    "y_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train_v2, x_test_v2, y_train_v2, y_test_v2 = train_test_split(x,y_log_df,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_v2 = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "neigh_v2.fit(x_train_v2,y_train_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_v2_pred_test = pd.DataFrame(neigh_v2.predict(x_test_v2),columns=['neigh_pred_test'])\n",
    "neigh_v2_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 - 1) RMSE with data splitting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_v2 = mean_squared_error(y_test_v2,neigh_v2_pred_test)\n",
    "MSE_v2\n",
    "RMSE_v2 = np.sqrt(MSE_v2)\n",
    "RMSE_v2\n",
    "log_RMSE_v2 = np.log(RMSE_v2)\n",
    "log_RMSE_v2\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} | log RMSE : {:.2f}\".format(MSE_v2, RMSE_v2, log_RMSE_v2))\n",
    "print(\"in this case, log RMSE is no meaning bacause we already used log scaled data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 - 2) RMSE with cv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "cv=5\n",
    "neg_mse_cv_v2 = cross_val_score(neigh_v2,\n",
    "                            x,\n",
    "                            y_log_df,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=cv)\n",
    "mse_cv_v2 = (-1)*neg_mse_cv_v2\n",
    "rmse_cv_v2 = np.sqrt(mse_cv_v2)\n",
    "#log_rmse_cv_v2 = np.log(rmse_cv_v2)\n",
    "\n",
    "#log_rmse_cv_mean_v2 = np.sum(log_rmse_cv_v2)/cv\n",
    "#og_rmse_cv_mean_v2\n",
    "\n",
    "rmse_cv_v2_mean = np.sum(rmse_cv_v2)/cv\n",
    "rmse_cv_v2_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 3 _std ->log(std) -> model -> log(pred) -> pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = []\n",
    "for i in range(len(y)):\n",
    "    y_log.append(np.log(y.loc[i]))\n",
    "    \n",
    "y_log_df = pd.DataFrame(y_log,columns=['stdval_log'])\n",
    "y_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train_v3, x_test_v3, y_train_v3, y_test_v3 = train_test_split(x,y_log_df,test_size = test_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_v3 = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "neigh_v3.fit(x_train_v3,y_train_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neigh_v3_pred_test = pd.DataFrame(neigh_v3.predict(x_test_v3),columns=['nei_pred_test_v3'])\n",
    "neigh_v3_pred_test_exp = np.exp(neigh_v3_pred_test)\n",
    "neigh_v3_pred_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_v3_exp = np.exp(y_test_v3)\n",
    "y_test_v3_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 1) RMSE with data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_v3 = mean_squared_error(y_test_v3_exp,neigh_v3_pred_test_exp)\n",
    "MSE_v3\n",
    "RMSE_v3 = np.sqrt(MSE_v3)\n",
    "RMSE_v3\n",
    "log_RMSE_v3 = np.log(RMSE_v3)\n",
    "log_RMSE_v3\n",
    "\n",
    "print(\"MSE : {:.2f} | RMSE : {:.2f} | log RMSE : {:.2f}\".format(MSE_v3, RMSE_v3, log_RMSE_v3))\n",
    "#print(\"in this case, log RMSE is no meaning bacause we already used log scaled data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하단코드 적용 불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "cv=5\n",
    "neg_mse_cv_v2 = cross_val_score(neigh_logdata_v2,\n",
    "                            x,\n",
    "                            y_log_df,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=cv)\n",
    "mse_cv_v2 = (-1)*neg_mse_cv_v2\n",
    "rmse_cv_v2 = np.sqrt(mse_cv_v2)\n",
    "#log_rmse_cv_v2 = np.log(rmse_cv_v2)\n",
    "\n",
    "#log_rmse_cv_mean_v2 = np.sum(log_rmse_cv_v2)/cv\n",
    "#og_rmse_cv_mean_v2\n",
    "\n",
    "rmse_cv_v2_mean = np.sum(rmse_cv_v2)/cv\n",
    "rmse_cv_v2_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version4 _feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape\n",
    "x_new = SelectKBest(f_regression,k=30).fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1 \n",
    "x_train_v4, x_test_v4, y_train_v4, y_test_v4 = train_test_split(x_new,y,test_size = test_size, shuffle = True)\n",
    "\n",
    "neigh_v4 = KNeighborsRegressor(n_neighbors = 5,metric='jaccard',weights = 'distance')\n",
    "neigh_v4.fit(x_train_v4,y_train_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nei_pred_v4 = pd.DataFrame(neigh_v4.predict(x_test_v4),columns=['pred_v4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_v4 = mean_squared_error(y_test_v4,nei_pred_v4)\n",
    "log_mse_v4 = np.log(mse_v4)\n",
    "log_mse_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 값이 더 크다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "cv=5\n",
    "neg_mse_cv_v4 = cross_val_score(neigh_v4,\n",
    "                            x_new,\n",
    "                            y,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=cv)\n",
    "mse_cv_v4 = (-1)*neg_mse_cv_v4\n",
    "rmse_cv_v4 = np.sqrt(mse_cv_v4)\n",
    "log_rmse_cv_v4 = np.log(rmse_cv_v4)\n",
    "\n",
    "log_rmse_cv_mean_v4 = np.sum(log_rmse_cv_v4)/cv\n",
    "log_rmse_cv_mean_v4\n",
    "\n",
    "#rmse_cv_v4_mean = np.sum(rmse_cv_v4)/cv\n",
    "#rmse_cv_v4_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 얘는 비슷. 더 나은 feature selection 필요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'a':[1,2,np.nan,4], 'b':[5,np.nan,7,8]}\n",
    "dict_df = pd.DataFrame(dict)\n",
    "\n",
    "dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.dropna(subset=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develroom-pytorch",
   "language": "python",
   "name": "develroom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
