{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioalerts\n",
    "from bioalerts import LoadMolecules, Alerts, FPCalculator\n",
    "import numpy as np \n",
    "from rdkit.Chem.Draw import IPythonConsole \n",
    "from rdkit.Chem import PandasTools, MolFromSmiles, AllChem\n",
    "from rdkit import DataStructs\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor #knn\n",
    "from sklearn.ensemble import RandomForestRegressor #RF\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. calculate significant substructure feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load IC50 values and smis into dictionary\n",
    "substD = {}#key = chemblID, val = (smi, bio)\n",
    "fr = open(\"data/5-alpha-reductase1_finalIC50.csv\", \"r\", encoding='UTF8')\n",
    "lines = fr.readlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    splitted = line.split(\",\")\n",
    "    smi = splitted[37]\n",
    "    bio = splitted[4]\n",
    "    chemblID = splitted[1]\n",
    "    if bio == \"\":\n",
    "        continue\n",
    "    substD[chemblID] = (smi, bio)\n",
    "    \n",
    "fr.close()\n",
    "#and shuffle the keys - usually dict does it for us but just do it(3.7 version of dict is ordered always)\n",
    "tmpItems = list(substD.items())\n",
    "np.random.shuffle(tmpItems)\n",
    "substD = dict(tmpItems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the data into smi_training, smi_test, bio_training, and bio_test\n",
    "tr_th = int(len(substD) * 0.8)#train has 80% of the whole data\n",
    "smi_training = {}\n",
    "smi_test = {}\n",
    "bio_training = {}\n",
    "bio_test = {}\n",
    "for akey in substD.keys():\n",
    "    if len(smi_training) < tr_th:\n",
    "        smi_training[akey] = substD[akey][0]\n",
    "        bio_training[akey] = float(substD[akey][1])\n",
    "    else:\n",
    "        smi_test[akey] = substD[akey][0]\n",
    "        bio_test[akey] = float(substD[akey][1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5159\n"
     ]
    }
   ],
   "source": [
    "#extract all substructures - see the code in LoadMolecules.py\n",
    "training_dataset_info = bioalerts.LoadMolecules.GetDataSetInfo(name_field=None)\n",
    "training_dataset_info.extract_substructure_information(radii=[2,3,4,5,6], smi_dict=smi_training)\n",
    "\n",
    "print(len(training_dataset_info.substructure_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the threshold for toxicity classification among the training data instances\n",
    "def calculate_bioactivity_threshold(bio, threshold):\n",
    "    sorted_bio = sorted(bio)\n",
    "    threshold_bio_value = sorted_bio[int(len(sorted_bio)*threshold)]\n",
    "    return threshold_bio_value\n",
    "\n",
    "threshold_= 0.6\n",
    "threshold_bio_value = calculate_bioactivity_threshold(list(bio_training.values()), threshold_)\n",
    "threshold_bio_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#extract substructures with high activity - see the code in Alerts.py\n",
    "Alerts_continuous_high_activity = bioalerts.Alerts.CalculateContinuous(radii_ext=[2,3,4,5,6])\n",
    "#the significant feature should be found only inside the training set.\n",
    "significant_substructure = Alerts_continuous_high_activity.get_significant_substructure_with_high_bioactivity(\n",
    "     smi_dict = smi_training,\n",
    "     substructure_dictionary = training_dataset_info.substructure_dictionary,\n",
    "     bioactivities = np.array(list(bio_training.values())),\n",
    "     mols_ids = list(smi_training.keys()),\n",
    "     threshold_nb_substructures = 5,\n",
    "     threshold_pvalue = 0.05,\n",
    "     threshold_ratio=0.2,\n",
    "     threshold_high_act_nb_substructures=7,#not used for now\n",
    "     threshold_high_act_ratio = 0.6,#not used for now                                                \n",
    "     threshold_bioactivity=threshold_bio_value)\n",
    "\n",
    "#threshold_high_act_nb_substructure = N of molecules involved significant substructure with high activity  \n",
    "#threshold_high_act_ratio = N of molecules involved significant substructure with high activity / N of molecules involved significant substructure\n",
    "#threshold_bioactivity = threshold defined above\n",
    "\n",
    "print(len(significant_substructure))\n",
    "#key, value\n",
    "#rdkit generated substructure id, chembl id\n",
    "#3454070996 ['CHEMBL15917', ... 'CHEMBL341004']\n",
    "\n",
    "rev_sig_substructure = {}\n",
    "for akey in significant_substructure:#key is a substructure id of rdkit\n",
    "    for chemblid in significant_substructure[akey]:\n",
    "        if chemblid in rev_sig_substructure:\n",
    "            rev_sig_substructure[chemblid].append(akey)\n",
    "        else:\n",
    "            rev_sig_substructure[chemblid] = [akey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. insert feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACCS fingerprint\n",
    "wholeD = {}\n",
    "fr = open(\"data/5-alpha-reductase-maccs.csv\", \"r\", encoding='UTF8')\n",
    "lines = fr.readlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    splitted = line.split(\",\")\n",
    "    bio = splitted[1]\n",
    "    if bio == \"\":\n",
    "        continue\n",
    "    wholeD[splitted[0]] =  [float(ele) for ele in splitted[2:]]#key is chembl id, and we exclude the bio(we already have it)\n",
    "fr.close()\n",
    "\n",
    "maccsD_training = {}\n",
    "maccsD_test = {}\n",
    "#yD = {}#we have already bio_training and bio_test\n",
    "for akey in wholeD.keys():\n",
    "    if akey in smi_training:\n",
    "        maccsD_training[akey] = wholeD[akey]\n",
    "    else:\n",
    "        maccsD_test[akey] = wholeD[akey]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#throught the testing, morgan is worse than MACCS - weird??\n",
    "morgan_training = {}\n",
    "morgan_test = {}\n",
    "radii_ext = [2,3,4,5,6]\n",
    "for akey in substD.keys():\n",
    "    mol = MolFromSmiles(substD[akey][0])\n",
    "    mfp = AllChem.GetMorganFingerprintAsBitVect(mol, max(radii_ext), nBits=1024)\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(mfp, arr)\n",
    "    #print(mfp)\n",
    "    if akey in smi_training:\n",
    "        morgan_training[akey] = arr\n",
    "    else:\n",
    "        morgan_test[akey] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "X_training, X_test = maccsD_training, maccsD_test#morgan_training, morgan_test\n",
    "X_training_wo, X_test_wo = copy.deepcopy(maccsD_training), copy.deepcopy(maccsD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the significant feature into train dataset and test dataset\n",
    "existsF =    [1. for i in range(100)]\n",
    "nonExistsF = [0. for i in range(100)]\n",
    "\n",
    "for akey in X_training.keys():\n",
    "    if akey in rev_sig_substructure:\n",
    "        X_training[akey] = np.append(X_training[akey], existsF, axis=0)\n",
    "    else:\n",
    "        X_training[akey] = np.append(X_training[akey], nonExistsF, axis=0)\n",
    "        \n",
    "for akey in X_test.keys():\n",
    "    if akey in rev_sig_substructure:\n",
    "        X_test[akey] = np.append(X_test[akey], existsF, axis=0)\n",
    "    else:\n",
    "        X_test[akey] = np.append(X_test[akey], nonExistsF, axis=0)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for y/bio values\n",
    "for akey in bio_training.keys():\n",
    "    bio_training[akey] = 9 - np.log10(bio_training[akey])\n",
    "for akey in bio_test.keys():\n",
    "    bio_test[akey] = 9 - np.log10(bio_test[akey])\n",
    "    \n",
    "#make lists of train_x, train_y and those of the test\n",
    "x_train, x_test, y_train, y_test = [], [], [], []\n",
    "for akey in X_training:\n",
    "    x_train.append(X_training[akey])\n",
    "    y_train.append(bio_training[akey])\n",
    "for akey in X_test:\n",
    "    x_test.append(X_test[akey])\n",
    "    y_test.append(bio_test[akey])\n",
    "\n",
    "#make above list without features\n",
    "x_train_wo, x_test_wo = [], []\n",
    "for akey in X_training_wo:\n",
    "    x_train_wo.append(X_training_wo[akey])\n",
    "for akey in X_test_wo:\n",
    "    x_test_wo.append(X_test_wo[akey])\n",
    "    \n",
    "#print(x_train[0])\n",
    "#print( x_train_wo[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.7107505198683638 (feature equipped) / 0.620211320461115 (without feature)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors = 5, metric='jaccard', weights = 'distance')\n",
    "#model training with all train data - with features\n",
    "neigh.fit(x_train, y_train) # > model train\n",
    "y_test_pred = neigh.predict(x_test) # > model predidction\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "\n",
    "\n",
    "neigh2 = KNeighborsRegressor(n_neighbors = 5, metric='jaccard', weights = 'distance')\n",
    "#model training with all train data - without features  \n",
    "neigh2.fit(x_train_wo, y_train) # > model train\n",
    "y_test_pred2 = neigh2.predict(x_test_wo) # > model predidction\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test, y_test_pred2))\n",
    "\n",
    "print(\"rmse:\", rmse, \"(feature equipped) /\", rmse2, \"(without feature)\")\n",
    "\n",
    "#1st-rmse: 0.6665674996275878(feature equipped) / 0.6506157409564809 (without feature)\n",
    "#2nd-rmse: 0.6616526937642756(feature equipped) / 0.6470203235135135 (without feature)\n",
    "#3rd-rmse: 0.7400772882780433(feature equipped) / 0.7191645589172299 (without feature)\n",
    "#4th-rmse: 0.5530300099595452(feature equipped) / 0.5530300099595452 (without feature)\n",
    "#5th-rmse: 0.6194732073893036 (feature equipped) / 0.5797533674300656 (without feature)\n",
    "#6th-rmse: 0.8833799018674932 (feature equipped) / 0.8712460159188644 (without feature)\n",
    "\n",
    "#conclusion - too much variance between performances + feature is not that helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.6108052363979027 (feature equipped) /  0.5945098451686438 (without feature)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RF = RandomForestRegressor(n_estimators= 30, random_state=0)\n",
    "#model training with all train data  \n",
    "RF.fit(x_train, y_train) # > model train\n",
    "y_test_pred = RF.predict(x_test) # > model predidction\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "\n",
    "RF2 = RandomForestRegressor(n_estimators= 30, random_state=0)\n",
    "#model training with all train data - without features  \n",
    "RF2.fit(x_train_wo, y_train) # > model train\n",
    "y_test_pred2 = RF2.predict(x_test_wo) # > model predidction\n",
    "rmse2 = np.sqrt(mean_squared_error(y_test,y_test_pred2))\n",
    "\n",
    "print(\"rmse:\", rmse, \"(feature equipped) / \", rmse2, \"(without feature)\")\n",
    "#1st-rmse: 0.5607542696180774(feature equipped) / 0.5951389693139828 (without feature)\n",
    "#2nd-rmse: 0.5456417432809881(feature equipped) / 0.5537994883596704 (without feature)\n",
    "#3rd-rmse: 0.6635918018542765(feature equipped) / 0.6596744885913872 (without feature)\n",
    "#4th-rmse: 0.6097764195923148(feature equipped) / 0.5979487754062859 (without feature)\n",
    "#5th-rmse: 0.5374167128801874 (feature equipped) /  0.5277560043097669 (without feature)\n",
    "#6th-rmse: 0.7463623098161197 (feature equipped) /  0.7443525413936887 (without feature)\n",
    "\n",
    "#conclusion - too much variance between performances + feature is not that helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3 SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
